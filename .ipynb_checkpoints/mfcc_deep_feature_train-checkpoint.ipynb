{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/media/hinton/work2.7/local/lib/python2.7/site-packages/librosa/__init__.py:40: DeprecationWarning: You are using librosa with Python 2. Please note that librosa 0.7 will be the last version to support Python 2, after which it will require Python 3 or later.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import sys\n",
    "# import pandas as pd\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.utils import to_categorical,Sequence\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History \n",
    "from keras.utils import plot_model,to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import dct\n",
    "# from iter_window import window \n",
    "import speechpy as sp\n",
    "# import statistics\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/DS_10283_853/protocol/CM_protocol/cm_train.trn'\n",
    "\n",
    "# open the file for reading\n",
    "filehandle = open(filename, 'r')\n",
    "train_protocol = []\n",
    "while True:\n",
    "    # read a single line\n",
    "    line = (filehandle.readline())\n",
    "    train_protocol.append(line)\n",
    "    if not line:\n",
    "        break\n",
    "\n",
    "# close the pointer to that file\n",
    "filehandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/DS_10283_853/wav/\n"
     ]
    }
   ],
   "source": [
    "train_protocol1 = []\n",
    "for i in train_protocol:\n",
    "    i = i.replace('\\n','')\n",
    "    train_protocol1.append(i)\n",
    "\n",
    "train_protocol = train_protocol1\n",
    "\n",
    "train_pd = []\n",
    "train_label = []\n",
    "for i in train_protocol:\n",
    "    j = i.split(' ')[1:2]\n",
    "    train_pd.append(j)\n",
    "    train_label.append(i.split(' ')[3:4])\n",
    "    \n",
    "train_pd1 = []\n",
    "for i in train_pd:\n",
    "    train_pd1.append(str(i)[2:-2])\n",
    "train_pd = train_pd1\n",
    "#import names of files in dataset\n",
    "path = r'/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/DS_10283_853/wav/'\n",
    "files = []\n",
    "missing=[]\n",
    "print(path)\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.wav' in file  :        \n",
    "            files.append(os.path.join(r, file))\n",
    "        else:\n",
    "            missing.append(file)\n",
    "\n",
    "#get train set\n",
    "file_name=[]\n",
    "for i in files:\n",
    "    i = i.split('/')[-1].replace('.wav','')\n",
    "    file_name.append(i)\n",
    "\n",
    "file_set = set()\n",
    "train_pd_set = set()\n",
    "\n",
    "file_set = set(file_name)\n",
    "train_pd_set = set(train_pd)\n",
    "\n",
    "train_set = file_set & train_pd_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code below ensures that train samples and train_labels are in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = []\n",
    "label_set = []\n",
    "for k in train_set:\n",
    "    for i in train_protocol1:\n",
    "        j = str(i.split(' ')[1:2])[2:-2]\n",
    "        if j==k:\n",
    "            label_set.append(j)\n",
    "            train_label.append(i.split(' ')[3])\n",
    "            \n",
    "np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/spoof_deep_features/train_label.npy\",train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "saving\n",
      "saving\n",
      "saving\n",
      "saving\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6d2fa419dae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_audio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/DS_10283_853/wav/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saving'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/hinton/work2.7/local/lib/python2.7/site-packages/librosa/core/audio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/hinton/work2.7/local/lib/python2.7/site-packages/librosa/core/audio.pyc\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mgcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mgcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/hinton/work2.7/local/lib/python2.7/site-packages/resampy/core.pyc\u001b[0m in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0minterp_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_ratio\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/hinton/work2.7/local/lib/python2.7/site-packages/resampy/filters.pyc\u001b[0m in \u001b[0;36mget_filter\u001b[0;34m(name_or_function, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             raise NotImplementedError('Cannot load filter definition for '\n",
      "\u001b[0;32m/media/hinton/work2.7/local/lib/python2.7/site-packages/resampy/filters.pyc\u001b[0m in \u001b[0;36mload_filter\u001b[0;34m(filter_name)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'half_window'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rolloff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/hinton/work2.7/local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    261\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/hinton/work2.7/local/lib/python2.7/site-packages/numpy/lib/format.pyc\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0m_check_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfortran_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_array_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/hinton/work2.7/local/lib/python2.7/site-packages/numpy/lib/format.pyc\u001b[0m in \u001b[0;36m_read_array_header\u001b[0;34m(fp, version)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;31m#   \"fortran_order\" : bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;31m#   \"descr\" : dtype.descr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/hinton/work2.7/local/lib/python2.7/site-packages/numpy/lib/format.pyc\u001b[0m in \u001b[0;36m_filter_header\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0mlast_token_was_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNUMBER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;31m# removing newline (see above) as python 2.7.5 workaround\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#To save audio data of trainset\n",
    "train_audio= []\n",
    "for count, i in enumerate(train_set):\n",
    "#     print(i)\n",
    "    j = i.split('_')[0]\n",
    "    train_audio.append(lb.load('/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/DS_10283_853/wav/'+j+'/'+i+'.wav'))\n",
    "    if count%1000==0 and count==1000:\n",
    "        print('saving')\n",
    "        np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/train\"+str(count)+\".npy\",train_audio[0:count])\n",
    "    elif count%1000==0 and count >= 1000:\n",
    "        print('saving')\n",
    "        np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/train\"+str(count)+\".npy\",train_audio[count-1000:count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save audio data of trainset\n",
    "from os import path\n",
    "train_audio= []\n",
    "missing_audio = []\n",
    "for count, i in enumerate(train_set):\n",
    "#     print(i)\n",
    "    j = i.split('_')[0]\n",
    "    if path.exists('/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/DS_10283_853/wav/'+j+'/'+i+'.wav'):\n",
    "        train_audio.append(i)\n",
    "    else:\n",
    "        missing_audio.append(i)\n",
    "\n",
    "train_set_list = list(train_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load npy files of the audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "path = r'/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof'\n",
    "print(path)\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.npy' in file and 'train' in file and '_' not in file:        \n",
    "            train.append(np.load(os.path.join(r, file), allow_pickle = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_format = []\n",
    "for i in range(len(train)):\n",
    "    for j in train[i]:\n",
    "        train_format.append(j[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_format= np.array(train_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trim the audio file to the mean length of all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_shape=np.empty(16000)\n",
    "for count,i in enumerate(train_format):\n",
    "    audio_shape[count] = len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75673\n"
     ]
    }
   ],
   "source": [
    "mean = int(audio_shape.mean())\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_audio = np.empty((16000,mean))\n",
    "padded_value =pad_sequences(trimmed_audio,maxlen=mean,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 75673)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC of the trimmed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc(signal,sample_rate,num_ceps):\n",
    "    pre_emphasis = 0.97\n",
    "    frame_size = 0.025\n",
    "    frame_stride = 0.01\n",
    "    nfilt = 20\n",
    "    NFFT = 512\n",
    "    emphasized_signal = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "    frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\n",
    "    signal_length = len(emphasized_signal)\n",
    "    frame_length = int(round(frame_length))\n",
    "    frame_step = int(round(frame_step))\n",
    "    num_frames = int(numpy.ceil(float(numpy.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
    "\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = numpy.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = numpy.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "\n",
    "    indices = numpy.tile(numpy.arange(0, frame_length), (num_frames, 1)) + numpy.tile(numpy.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(numpy.int32, copy=False)]\n",
    "    frames *= numpy.hamming(frame_length)\n",
    "    mag_frames = numpy.absolute(numpy.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
    "    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))\n",
    "    low_freq_mel = 0\n",
    "    high_freq_mel = (2595 * numpy.log10(1 + (sample_rate / 2) / 700))  # Convert Hz to Mel\n",
    "    mel_points = numpy.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
    "    hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
    "    bin = numpy.floor((NFFT + 1) * hz_points / sample_rate)\n",
    "    \n",
    "    fbank = numpy.zeros((nfilt, int(numpy.floor(NFFT / 2 + 1))))\n",
    "    for m in range(1, nfilt + 1):\n",
    "        f_m_minus = int(bin[m - 1])   # left\n",
    "        f_m = int(bin[m])             # center\n",
    "        f_m_plus = int(bin[m + 1])    # right\n",
    "    \n",
    "        for k in range(f_m_minus, f_m):\n",
    "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "    filter_banks = numpy.dot(pow_frames, fbank.T)\n",
    "    filter_banks = numpy.where(filter_banks == 0, numpy.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "    filter_banks = 20 * numpy.log10(filter_banks)  # dB\n",
    "    mfcc = dct(filter_banks, type=2, axis=1,n=num_ceps, norm='ortho') # Keep 2-13\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28260"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60*471"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n"
     ]
    }
   ],
   "source": [
    "delta = []\n",
    "delta2 = []\n",
    "value = []\n",
    "mfcc_feat_train = np.empty((16000,28260))\n",
    "shape = []\n",
    "mean_value = []\n",
    "\n",
    "for count,f in enumerate(trimmed_audio):\n",
    "    delta=np.array(lb.feature.delta(mfcc(f,16000, num_ceps=30)))\n",
    "    delta2=np.array(lb.feature.delta(mfcc(f,16000, num_ceps=30), order=2))\n",
    "    value = np.concatenate([delta,delta2], axis=1)\n",
    "#     print(value.shape,delta.shape,delta2.shape)\n",
    "#     shape = np.append(shape,(value.shape[0]))\n",
    "    mean_value = sp.processing.cmvnw(value).reshape(1,-1)\n",
    "#     padded_value =pad_sequences(mean_value,maxlen=74340,dtype='float32')\n",
    "    mfcc_feat_train[count] = mean_value\n",
    "\n",
    "    if count%100==0:\n",
    "        print(count)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 28260)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_feat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/mfcc_train_padded.npy\",mfcc_feat_train,allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading trim audio padded mfcc features for chunking and windowing to feed it into the DNN to get the BNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/mfcc_train_padded.npy\",mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/spoof_deep_features/train_label.npy\")\n",
    "\n",
    "train_labels=list(train_labels)\n",
    "\n",
    "train_labels1 = list()\n",
    "for i in train_labels:\n",
    "    if i == b'human':\n",
    "        train_labels1.append(1)\n",
    "    else:\n",
    "        train_labels1.append(0)\n",
    "train_labels = to_categorical(train_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x=data_train[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = []\n",
    "for i in batch_x:\n",
    "    window_train.append(np.array(list(window(i,7,7))).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423900,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window( iterable, left, right, padding=0.0, step=1 ):\n",
    "   \n",
    "    from itertools import islice, repeat, chain\n",
    "    from collections import deque\n",
    "\n",
    "    n = left + right + 1\n",
    "\n",
    "    iterator = chain(iterable,repeat(padding,right)) \n",
    "    \n",
    "    elements = deque( repeat(padding,left), n )\n",
    "    elements.extend( islice( iterator, right - step + 1 ) )\n",
    "\n",
    "    while True: \n",
    "        for i in range(step):\n",
    "            elements.append( next(iterator) ) \n",
    "        yield tuple( elements ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chunking_windowing(Sequence):\n",
    "    def __init__(self, data_train, train_labels, batch_size):\n",
    "        self.data_train = data_train\n",
    "        self.train_labels = train_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.n = 0\n",
    "        self.max = self.__len__()\n",
    "        self.window_train = []\n",
    "    def __len__(self):\n",
    "        return np.ceil(len(self.data_train) / float(self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.data_train[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.train_labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        for i in batch_x:\n",
    "            self.window_train.append(np.array(list(window(np.array(i),7,7))).ravel())\n",
    "        return np.array(self.window_train), np.array(batch_y)\n",
    "    def __next__(self):\n",
    "        if self.n >= self.max:\n",
    "            self.n = 0\n",
    "        result = self.__getitem__(self.n)\n",
    "        self.n += 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_generator = chunking_windowing(data_train, (train_labels), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[423900,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam/beta_1/read, training/Adam/Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training/Adam/gradients/loss/dense_6_loss/clip_by_value/Minimum_grad/Reshape/_173 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_454_t...ad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e28b0a8bd247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                                           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                           max_queue_size=1)\n\u001b[0m\u001b[1;32m     24\u001b[0m get_5th_layer_output = K.function([model.layers[0].input],\n\u001b[1;32m     25\u001b[0m                                  [model.layers[4].output])\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[423900,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam/beta_1/read, training/Adam/Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training/Adam/gradients/loss/dense_6_loss/clip_by_value/Minimum_grad/Reshape/_173 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_454_t...ad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "#define neural network\n",
    "output = []\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(1000, activation='sigmoid', input_shape = (423900,)))\n",
    "model.add(Dense(1000, activation='sigmoid'))\n",
    "model.add(Dense(1000, activation='sigmoid'))\n",
    "model.add(Dense(1000, activation='sigmoid'))\n",
    "model.add(Dense(64, activation='linear'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "layeroutputs = []\n",
    "# for i in pad_window:\n",
    "# model.fit(data_train, to_categorical(train_labels1[0:16000]), epochs = 10,batch_size = 64)#, callbacks = callbacks_list, validation_data=(x_validation,y_validation))\n",
    "model.fit_generator(generator=training_batch_generator,\n",
    "                                          steps_per_epoch=16000 // 50,\n",
    "                                          epochs=10,\n",
    "                                          use_multiprocessing=True,\n",
    "                                          workers=16,\n",
    "                                          max_queue_size=1)\n",
    "get_5th_layer_output = K.function([model.layers[0].input],\n",
    "                                 [model.layers[4].output])\n",
    "output = get_5th_layer_output([data_train])[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/MFCC_BNF.npy\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Labels\n",
    "## 1 : Human and 0 : spoof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_embedding=np.load('/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/MFCC_BNF.npy')\n",
    "train_labels = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/spoof_deep_features/train_label.npy\")\n",
    "\n",
    "train_labels=list(train_labels)\n",
    "\n",
    "train_labels1 = list()\n",
    "for i in train_labels:\n",
    "    if i == b'human':\n",
    "        train_labels1.append(1)\n",
    "    else:\n",
    "        train_labels1.append(0)\n",
    "train_labels = train_labels1[0:16000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 12326, 1: 3674}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(train_labels, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3674\n",
      "12326\n",
      "[-0.0396288   0.08848841 -0.14787385 -0.00349256 -0.16794349  0.1121874\n",
      "  0.00196716 -0.15601198  0.19408454  0.03751769 -0.02068959 -0.02990031\n",
      " -0.01520616 -0.13030709 -0.00366588 -0.02238522  0.03692608  0.00523918\n",
      " -0.03178951 -0.18017225 -0.11210369  0.08550716 -0.01765143  0.20545204\n",
      " -0.01184154 -0.03608226 -0.01512863  0.27813613 -0.12054816  0.05609776\n",
      "  0.04479205  0.00692885  0.00513153 -0.09709889  0.0712918  -0.0103248\n",
      " -0.13582321  0.19183233 -0.19657315  0.14229555  0.26224723 -0.00241501\n",
      " -0.0403846  -0.10861277 -0.04322349  0.01052263 -0.0622784  -0.00979339\n",
      "  0.04943707  0.29097745  0.07369728  0.30887079  0.00253626 -0.08361564\n",
      "  0.00124436  0.12283443 -0.06048156 -0.01331422 -0.25498566  0.28456143\n",
      " -0.02653572 -0.00208196 -0.24684517 -0.03100653]\n"
     ]
    }
   ],
   "source": [
    "j , k = 0,0\n",
    "# human_samples = np.empty((3674,17880)) # wrong array size as BNF is of size 3674,64\n",
    "human_samples = np.empty((3674,64))# corrected\n",
    "human_labels= []\n",
    "# spoof_samples = np.empty((12326,17880))\n",
    "spoof_samples = np.empty((12326,64))\n",
    "spoof_labels = []\n",
    "for count,i in enumerate(train_labels):\n",
    "    if i ==0:\n",
    "#         human_samples=np.append(human_samples,data_embedding[count])# Do not append insert the data at that position\n",
    "        human_samples[j]=data_embedding[count]\n",
    "        human_labels.append(train_labels[count])\n",
    "        j = j+1\n",
    "    elif i ==1:\n",
    "#         spoof_samples=np.append(spoof_samples,data_embedding[count])\n",
    "        spoof_samples[k] = data_embedding[count]\n",
    "        spoof_labels.append(train_labels[count])\n",
    "        k = k+1\n",
    "        \n",
    "print(len(human_labels))\n",
    "print(len(spoof_labels))\n",
    "print((human_samples[3]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/human_samples.npy\",human_samples,allow_pickle=True)\n",
    "np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/spoof_samples.npy\",spoof_samples,allow_pickle=True)\n",
    "np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/human_labels.npy\",human_labels)\n",
    "np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/spoof_labels.npy\",spoof_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GMM for human samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_samples = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/human_samples.npy\")\n",
    "human_labels = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/human_labels.npy\")\n",
    "spoof_samples = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/spoof_samples.npy\")\n",
    "spoof_labels = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/spoof_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GMM(n_components=1280).fit(human_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GMM for spoof samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_spoof = GMM(n_components=1280).fit(spoof_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate predicted values for the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_embedding=np.load('/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/MFCC_BNF.npy')\n",
    "train_labels = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/spoof_deep_features/train_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=list(train_labels)\n",
    "\n",
    "train_labels1 = list()\n",
    "for i in train_labels:\n",
    "    if i == b'human':\n",
    "        train_labels1.append(1)\n",
    "    else:\n",
    "        train_labels1.append(0)\n",
    "train_labels = train_labels1[0:16000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "llr_natural = gmm.score_samples(data_embedding)\n",
    "llr_spoof = gmm_spoof.score_samples(data_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([375.37624562, 374.97963942, 378.52538313, ..., 377.53224634,\n",
       "       304.5453829 , 371.4250415 ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llr_natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([375.27032239, 375.01014885, 378.10286576, ..., 377.48968628,\n",
       "       370.73648679, 370.14560233])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llr_spoof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "llr_score = llr_natural - llr_spoof     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.empty(16000)\n",
    "for i in range(len(llr_score)):\n",
    "    y_predicted[i] = int(llr_score[i]>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(train_labels, y_predicted)\n",
    "eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "thresh = interp1d(fpr, threshold)(eer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35979931981977703"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(train_labels,y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7014705340694123"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzs3Xd0FUX/x/H33JubHtJ7IAFCr9IElaIUsWEFC1VFkKKPCCgqiIIoIlVBBFGpooBKkY7Sm/SOBEJCAklI7+WW+f1xIYIF4k8gQL6vc55j7u7s3pl9Dp9MZndnlNYaIYQQZYOhtCsghBDixpHQF0KIMkRCXwghyhAJfSGEKEMk9IUQogyR0BdCiDJEQl8IIcoQCX0hhChDJPSFEKIMcSjtCvyZn5+fjoiIKO1qCCHELWXPnj0pWmv/q5W76UI/IiKC3bt3l3Y1hBDilqKUii1JORneEUKIMkRCXwghyhAJfSGEKEMk9IUQogyR0BdCiDJEQl8IIcoQCX0hhChDJPSFEKIMkdAXQogyREJfCCHKEAl9IYQoQyT0hRBXlXIujaTY5NKuhrgGbroJ14QQN58+Dd4gKzWb5XnzcDBJbNzK5P89IcRVte3Wkuy0bIwOxtKuiviPJPSFEFfVa0zX0q6CuEZkTF8IIcoQCX0hhChDShT6Sqn2SqnflVInlVJD/mZ/C6XUXqWURSn11J/2jVFKHVFKHVNKfaqUUteq8kIIIf6dq4a+UsoITAEeAGoCzyqlav6p2BmgB/Dtn469C7gbqAvUBhoDLf9zrYUQQvy/lORGbhPgpNY6GkAp9R3wKHD0YgGtdcyFfbY/HasBZ8ARUIAJSPrPtRZCCPH/UpLhnVAg7pLP8Re2XZXWejuwHki48L/VWutj/7aSQgghro3reiNXKRUJ1ADCsP+iuE8p1fxvyvVSSu1WSu1OTpa3/oQQ4nopSeifBcpf8jnswraSeBzYobXO0VrnACuBZn8upLWerrVupLVu5O/vX8JTCyFKg9VqZfaIhez79VBpV0X8P5Qk9HcBVZRSFZVSjsAzwNISnv8M0FIp5aCUMmG/iSvDO0LcwuJPJDDnvQXMGDIXAK01+bkFpVwrUVJXDX2ttQXoD6zGHtgLtNZHlFIjlFIdAJRSjZVS8UBHYJpS6siFwxcBp4BDwAHggNZ62XVohxDiBqlQPZRhC17nzdmvAjD2hc/p4NGV+KiEUq6ZKIkSTcOgtV4BrPjTtncv+XkX9mGfPx9nBXr/xzoKIW4iSilaPPXHKG1wpUACKvjh4u5cirUSJaW01qVdh8s0atRI7969u7SrIYQQtxSl1B6tdaOrlZNpGIQQ14y5yIzVYi3taogrkNAXQlwTFrOFjkE96dPwjdKuirgCmVpZCHFNKIMiKCIAv1Cf0q6KuAIJfSHENWE0Gvli7yelXQ1xFTK8I4S4IQ5tPsZrzYcSf+JcaVelTJPQF0LcEPt+PcSRrb8Ttfd0aVelTJPhHSHEdWe1Wmn//L3c1aExletHlHZ1yjTp6QshrrupA2bSOaIvRQVFyDpKpUtCXwhx3VVrFEmFGqEUFZl51Lsbs4Z/X9pVKrMk9IUQ113bbi356shEonZHk5eZz28r9pZ2lcosGdMXQtwwLZ5qxr5fD9Nl2FNXLyyuCwl9IcQNExjuz4fL3y7tapRpMrwjhCg1BXmFTH9jNjFH465eWFwTEvpCiFLz44SfWTh2GUPajcRqlYnabgQJfSFEqWnbvSXegZ6knkvnSf8XiL0GPf4tP+2kX+M3SYqV9bb/joS+EKLU+If58dGqofiF+pCbkUdWas5/Puf+9Yc5sSeac6cSr0ENbz+yiIoQotRprcnNzMPdy+0/n8titpAYk0xYleBrULNbhyyiIoS4ZSilrkngAziYHMpc4P8bEvpCiJuOrWAj1oQaFGYsLe2q3HYk9IUQN51VX2/n/RfC+P6TNZdtP3sygWfL92Zoh49KqWa3Pnk5Swhx0/n6vRNkpnjhEVzjsu1jX/iclLNpGE1GUhPSyc8pkKGcf0l6+kKIm06leuEYTUY6D3uKTYu289NnKwCo36oWAHc/1oT/3fUOz1d7lfyc/OLj9v16iDfbjWDbst086tWNNbM3lEb1b2rS0xdC3HQCw/0xGI6jtGZkp/EAtO7cnC7DO1K3VS1qNK2Kh487506cwNF0EqgDwLYlu9i77hD1WtUmLyufvKz8K3xL2SSPbAohbko2m41Dm48x6N73AGjXoxWDv+53eZmkJqAzUIGHUcqRooIiTuw5RVjVENAw6rmJhFUNZuviXYxeNZRKdcNLoSU3hjyyKYS4pRkMBmrfUx1HZxMAyWdS+HLIXKIPxhaXsbr0o/+Dd/F6y5GYi8w4Ojsyb+QPdAzsye+7TrL/18Mc2nSM9MQMstP/+4tftwMJfSHETctoNDJq+dvUbl6dfb8eZsGYJXzc/TMujlAol86cPlrI4S3HebPdSABqNKtK5B0VMTmbaNCmLu8tfoNRK97i/SfHsn2ZjCJI6Ashbmr+5X1p/kTT4s/RB2I5sfsUWmscTA68MbMfDo4OBEYE8NuqfXR+50mm7hnDjmV72LvuIKcPxFKUZyY7LYfk+NRSbMnNQUJfCHFTG/74J0wdMJMXPnqOGk2r4OTiSP8732L59HUA3PvMPSzNms262Rt558EPGddzKgDPf/AMH699l7sfb4LVYp/BM+742VJrx81CQl8IcVPr/n4nOg3qQKdBHRgwrTeF+UU4OpvY/MMOcrPyADA5mug6vCPlfN3ZuGAbXw39Fhd3Fxq0roPBYKBy/XAq1qlAaGQwE3p/Qfr5zFJuVemR0BdC3NSaP9GUl8Z0xWg0UrFOOD+kfE3j9newd91BTu47XTwPf7fhnQivVZ6iAjPLpqy+7BxHtp3g9KEzrJ61gRVf/sK2JbtKoyk3hRKFvlKqvVLqd6XUSaXUkL/Z30IptVcpZVFKPfWnfRWUUmuUUseUUkeVUhHXpupCiLKonI8HA6b3ZvTqoXw/ZgmPeXUnJyMXgNem9gLAYLw82lo81ZS+E5/nydceAmDp56u42R5Xv1Gu+nKWUsoITAHaAvHALqXUUq310UuKnQF6AIP+5hSzgVFa67VKKXfA9p9rLYQo0zz9ytGwbT12rVjCvQ/FY1DngYpUqBFGnwk98A31uay8i7sLj7/6IFmp2ZicTUQfiCU+KgG/UB+2L91NxToVqFi7Quk05gYryRu5TYCTWutoAKXUd8CjQHHoa61jLuy7LNCVUjUBB6312gvl5EFZIcQ102ukP+ScQzlsASoC8MT/HvrH8kWFZp7/4BlO7jvNC9X/h9HBgNVio0rDSny+6+MbVOvSVZLhnVDg0jXM4i9sK4mqQIZS6kel1D6l1CcX/nK4jFKql1Jqt1Jqd3KyLHEmhCgh5Q0uPcC1Y4mKT+oznemD5hBSOQijoxGD0Ujte6qTcT6TpZ+vZvobc7DZbu/BiOt9I9cBaI592KcxUAn7MNBltNbTtdaNtNaN/P39r3OVhBC3A60tkP0uFCxEKecL2zS71xwgKy37T2U1UXujeeyVB3i0f3s6DX6Uux6ug7nQjJOLleS4VOZ//CMLxy7ll3mbS6M5N0xJQv8sUP6Sz2EXtpVEPLBfax2ttbYAi4EG/66KQgjxV0o5oLyno7ymFm/bu+4gb7X/gMmvfF28LT+3gDkjFtK30Zss/XwN/T99ERc3Z96cXoFZO48y8vsQFqfPpM/45wHYtHD7DW/LjVSSMf1dQBWlVEXsYf8M8FwJz78L8FJK+Wutk4H7AHkPWghxTSinVpd9rtqoMq27tODBnq2Lty0ct5Q57y8EIGrPqeLtjt6dCK7tw76t/nwzbBRvzn6FiVs+oHz1kBtS99Jy1Z7+hR56f2A1cAxYoLU+opQaoZTqAKCUaqyUigc6AtOUUkcuHGvFPrTzi1LqEKCAL69PU4QQZZ2HtztDZr9C3RY1i7e1fKoZodUCeXnEWWo3jmLrhWf0lXJCuTzEwY2nOL4zitOHzlDrrmqg7X8d3K5kamUhxG1vyWezeKTjKHIyDZw4/jCLZ/hy5thZZhyZgNFoIOZIHPt/PUyVRpV5o/X7hFUNZsbhCaVd7X9FplYWQogLHn2lO9pjIu6eNhrcE0duZh7ZaTmgNUYHIzarjS8GzuKrt+ZR/c4q2Gy2y6Zwvp3IyllCiDLB6PYg2qkmGHwZv9Edm82G0Wh/gjy0ajAhlYOIrB9BzWbVGN31Uz7qOokvD4znfFwKRQXm22YtXgl9IUSZoRwiin++GPgHNhzh5+lrOXcqkZ0rrDz+2oMYHAykncsAoF/jIWQmZ7E8fx4mR1NpVPuaktAXQpQ5SbHJbPh+G3e0qc3CcUvZuXwvHfrez9LPV7N82jq8/D1JS0jnkxcmc3+PVuRm5uFguj3i8vZohRBCXKIgr5A32rxP/Xtr88Koy58w/+mzFaydvZGoPdEAhFQO5IOf36L2PdUJqRxEy07NcHJ1Yvn0tayZuZGQyoHMippcGs24LuRGrhDitpOfnc+xHVEc2nzsL/u+/fDH4sAHaNiuHnc+2AC3cq48OeBhHBwdCAr3p/e47gCcO5V0W83IKT19IcRtxzvQi4VJM3D1cPnLvgkbR5CfU8BvK/ex5cedJJ4+j81mY8eyPVRrEsnCsUv4YcJyGrSpAwrav3AvSikAUhPScfdyxcnF6UY36ZqRnr4Q4rZ0YMNRHvXqxqIJyzi8xd7jt1qthEQGUaVBJTq/8yTZaTkc2HCEtXM2MvzxMXSL7M9djzXB3csNq1VTzseDZ4Y8zok9p3ix5ms8E9qLYR0+Zunnq9i29NZciEV6+kKI29Kqb37FUmRl2sDZACzNnkOXiL4EVQxgym+jAZh+cBxWi5VP+80AoCi/CHdPN3IycgkM96NyvXB6VHkVAGc3JxydTdRsVpXP+n+Fs7sTy7Lmlk7j/gPp6QshbkvGS1bPqtmsCslxKWSlZl+2Pq6rhwse3u7UalYFAIODgUp17Usy3vlQA36cuBwAk5ORvp9EsjR7Js++9TjALTvEI6EvhLgtvb/4Dabu+wRHV0eObo/CZtW4e7nRpkuLv5S9//n7uPe5e3ByduTlBoOZ1OdLvAM9KefrDoC50EpY6GIM1qOcOXaWLsOe4uXx3W/JG7wyvCOEuC0ZjUYi60UQWjmI04fOEH/iHD+lzfzbsi7uLjzSuy3rv93Cqf0xnNofg6OziazUHIIqBtBp4F3kWZPpecdMkuNSyc+xT8hWoXooVRtWvoGt+u8k9IUQt7W35r7KmtkbmTX8e9bP38KwBQP/tpyL+x9P+ji5OLL+uy28/9NgEk4n82n/mTg4GrEUWTEYDZicTZgLzIRWCbpRzbhmZHhHCHFbq1gnnB7vP0JidDwJp07/Y7nIOypidLBHooOziaqNItm5Yh8N2tSh6cMNCa8RBthX4Zp14jNmn5yMs5szx3aeIPZo3D+e92YjoS+EuO05Go+z8PABJq26crmvjk3k8f89yJcHxmI0Gljx5TqUUoxcOoS4388BYDAojm4/QXClQOaOWMSrzd6hZ+3XL7tBfDOT0BdC3P4cm+IUNBUHn/euWKxf4yGs+vpX/MP8eGf+a3zyy3AiatlXi63b0r4wi9ViY+7IRQDUbFYV3xBv7nyoAeV83K9rE64VGdMXQtz2lFKYDc0xGa88S+bdjzYhJzOXTsE9efL1R3h68KPF+9p1v5fdqw8AkBiTRE5GLo3b38F38dOva92vNenpCyFuewc2HuFB5+d4xL0zX775zy9UDf6mH2kJ6aQnZbL4sxUUFZpJP5+JuciMu7cbHt5uhFYLolWHc/wwZtQNbMG1I6EvhLjtObs54+bpSkF+ETkZuVcsm5WaA0BKfBprZq2nU1BPnvB7ARd3Z95f/CaYYxkwNp672yxHa01e+nZsud/fMs/sy/COEOK2V61RZRanz8JqsT9yeSVT945hQPNhRB+IxdnNGf/yviTHpRJzOI4WHZsSXudujhxuSFBkC2IOn0Gn9iKieiE4NQOHCjeoRf9/sjC6EKLM2LV6P4Hh/lSoHnrFcsnxqXz/8WKWTFlFr7FdqdWsGpXvqIjVbKWooAgvf0/APmw0c8gQHnwhnDY9PyuejfOfHN3+OwnR52ndufk1a9NFJV0YXXr6QogyITk+lbcfGEX56qF8fXTiFcv6h/lyR+s6LPtiDdMHzQGgcfs7iDlyhtRz6SzJnI2zqxNZqTkc3ulM3dZ3XzXwAUZ3/YyE6CTq31cb32Dva9Kuf0tCXwhRJviGeNN56JNUaVAJsK+udWDDERq2rVu8FGJuVh5Ws5Vyvh4c/+0krh4uOLqY8PB2p3bzauxatQ8UvPv4GF76qDP3PN6E6QfHXfUvh4sGzujD2agEfIK8rls7r0aGd4QQZdLs9xYwZ8RCXv/yZR54sTUA3SL7kRyfxpLM2Qx75CP2rjuEycmBt799jWYdGtGv0Zvk5RSQcCoJDx93fkz5ppRb8QcZ3hFCiCto/uSdxP1+lgZt6hZvK18tFJtVo7Wmz4Tn2fnzbma89S3vPzkWz4ByZKVkE1jBn+p3RpKfXcCetQdo2LZeKbbi35NHNoUQZVLFOuG8M38AuZl5TBs8m9zMXPJyCkiKTSb+93MMuX8kM976Ft8Qb7wDPck8n4W2acb88i4Dpr1M7NF45o74vrSb8a9J6AshyrQfJy1n0bhl7Pv1MG/O6s+IJW9SqW44kXdUBOxTLXx/7ksefrktngHl+LjbZJZ+vgqDAzzZcxWrZszi8Nbj2Gy2Um5JycjwjhCizEo4nUTK2TS6v/80TR9uiIPJAYNBsWj8zzR/sik7l+/FXGhh08LtpCVkkHk+i8zzWRTlF4INpg0vT+KZn4GfeXP2K3+7QMvNRnr6Qogy69CmY+xZcwCrxVL8BM/3nyxl+uDZOJgc+CltJvFR5/jgmQns+/UQJhf73D1nTyVgs0FSvBMtOjajbsua1GhapTSbUmLS0xdClFmtuzQnoIIfNZtVLd72cK82JMelUOvuqrh7uRFRuwLxvyeQn12AydkemQU5hQBom6ZBmzpUrhdBaGRwqbTh3ypRT18p1V4p9btS6qRSasjf7G+hlNqrlLIopZ76m/3llFLxSqnJ16LSQghxLRiNRsKqBpMUm1y8bf/6I2xfupvP+n9Fwukk3pr7P57/4BkAKkTa58wPrexXXH7Wu9/zStO3+X33qRtb+f+nq/b0lVJGYArQFogHdimllmqtj15S7AzQAxj0D6cZCWz6b1UVQohr7393D+X8mRQq14/g2bcex83LlUp1w/ltxT4mmqdzcMMRAir48d4P3fBxHsrc8SFENLifuE9W4+LhTHpSJuWrhRBW9dbo6ZdkeKcJcFJrHQ2glPoOeBQoDn2tdcyFfX+5fa2UaggEAquAq744IIQQN1K9VrVYO3sjp/bHsPTz1RzcaI82ZVCcO5lIjYaZaFsmLu4BfDu2Ar/94sy5+IMA5GfbF0hPjk/FrZxrqbXh3yhJ6IcCly4AGQ/cWZKTK6UMwDigC9DmCuV6Ab0AKlS4+WepE0LcPvp9+gJunq7UaVGToztOcHDjUSrXD0fboPqdobwyfC1WC6xbncWOtc4A5F8Y07/IN8SHYzuj+Kz/DAZM61081cPN6Ho/vdMXWKG1jr9SIa31dK11I611I39//+tcJSGE+INbOVf6TXoBdy83fhi3DICslBzOx6XwYFdXDAbIyoxgzawNACgFWanZ1LizCvXurQXA2agEFo5dStSeaKL2/vPi6zeDkoT+WaD8JZ/DLmwriWZAf6VUDDAW6KaUGv2vaiiEEDeAX6gPIZFB3NG6Dk0ebEBOei6r5pkpMg0ho2AoR7edIDDcj2aP1CYw3I9qTSLJSMrkrscaA+Ad6MmMw+N54MX7SrklV3bVCdeUUg7ACaA19rDfBTyntT7yN2VnAj9rrRf9zb4eQCOtdf8rfZ9MuCaEKC35uQWsmbmBZh0a0jm8L0rZV9368vB4ukT0BaB20xwO73DHO8iT9MRMvj0zlcJ8MyGVAzEYSu/Vp5JOuHbVGmqtLUB/YDVwDFigtT6ilBqhlOpw4csaK6XigY7ANKXUX34hCCHEzWba4Nn8PG1N8ef187cy+ZWvmDfqJ1p0aobBaKB8NW9cDRNwdLYCmsxUEwYj9JnQnUXnv8I/zI+wKsGlGvj/RolqqbVeobWuqrWurLUedWHbu1rrpRd+3qW1DtNau2mtfbXWtf7mHDOv1ssXQogb5czxsywat4xP+81Aa82Ip8YyodcXdOjXnuzULDYt2I7VYqNcuZO4OSxi0MQ4QBEX5cR9z93Dh89+yoTeXxSfb/MPO3jctweHNh8rvUaVgLyRK4Qok8KqBtPq6buoWKcCa2ZtYPOPOwF48rWHKMgtJKhiIL/M28yeDZpsy9ssn/sDvkFmUhNNrJuzBYBDm49jLjJjcjSRk5FLTnouedn5pdmsq7o1/h4RQohrzGAw8M78ATz39pP4htiXLnTzdCWkchCV6obTa0xXQiID0VqRnh7J2VMGHBxt3PNQevE5TCYHHnbrwvm4FGrdVY0uw56iQZs6pdWkEpGevhCizLujdR0ee+UBqjasXLztt5V7SYpJJjDCn6kDfyU705WnXj7PvPE+GIwam1URGOEPChJPn2fUMxNIS8zAtZwLHQd2KMXWXJmEvhCiTDm2M4rV36yn5+jOuHu5AfY5ePpNeuGyclMHzCQ5LhWApBj73Dy7tzUCTmGzKnqP7Ubbbi3ZvnQ3A1sNJyQyiMBwP1o9ffcNbc+/JaEvhChTlkxZyS9zN5OWkM6Z388yfuMIfAK90Fpz/LeTBFX0x9OvHMMWDGTHst3M/WABPYakEXMimLXzo/EMsK+i5RvqTefwPthsNty8XDl3MhHPgHL4h/mWdhOvSMb0hRBlysvjuvPej4OJPRbH2RMJ9Kw9AICdK/byarO36RT0Eg84PYtGs3fdQZo95MVTvWN57rXzALR4qhkd+t3Ph89OwifYG3OhBS687tT8iaal1awSk56+EKJM8fL35O7HmvBp3y8B8An0BCDm0JniMjarjemD53Boy3FsViu6KJxzceFAGrXvroZSin2/HObdBS8ReyyLUc9MAKDXJ11ueHv+LQl9IUSZNHb9e2z6YQchlQJJOJ3Eqpnri/d5B3rSqF199q49iMHBwOafvYA0AGa++z2Tto2iSs2DhPg9TvjD4/Fe/x55WXm4uLmUUmtKTkJfCFEmla8WiqOTiQ+fmwSA44WlEB0cHcjPKWDvL/bpk20W+9iNMii0TZMUk0ynwJ7UvycbJ5cqWPRGPlr9EDabjW6R/fAJ9mHi5pGl06gSkDF9IUSZ9cPEn1FKg9IU5Zvp0CuIOacmM37TSI5sOY7J2YGu73YE7EsjfvP7JD5c8TbKoNi/xYNdv7pxfLd9rB8N5kILVrOlFFt0ddLTF0KUOVsW72Tzop2YHE0EhRdSqUYBAWFmHn/xKFt+vIcF4zaQn2NfIGXhuKUA3P1YE0IjgwkJ2cyKjF5MHRJD4unz/LZyH90i+zNm7bt8e+aLK33tTUFCXwhRZthnFTaz7PM17F138MJWJ175OJ+RL/iQlt6M/RtWk5mSXXxMQW4hFWqE8lCvNtxveprnXkug2xsWXpm8nWVTV3Nw01EST58nOT6V4EqBpdKuf0OGd4QQZUJqQjrJhx9FJ9Xm7Zl16TvxefzL++LgaCK86Xc88Vondq6MIzMlG2UEZzen4mPPHDtL0pkUtM3G7g0BJGeNYuvi33j45XYszpjFt2e+oG6LmqXYupKT0BdC3Pai9kbTpWJfln6ZQXaGgQXjtvL5a9+QHJdKx0GPYDAvp9uQImrfXR0AbQWTswml/jhHpdrlWH3uIKMXFTGuzxbee+ITulTsi6XIctO/kHUpGd4RQtz2zp9JwVJk4fvJgXw/ORD4Y0nDpVNWkXIynt7vJeBgagUK0KCtmotrTA3/YRAWi4mEuBBSM+oTEhlE3PGzpCdlYjFbcbr5n9QsJqEvhLhtjekxmUObj1GlYUUefOk+Nv2wk5y0XACMDkasViu5mfmsXeBLUYGBgR9vYII1jIM7Qhg0sx/bFv/GnjUHKF8thC/fnMvO5f5E1M4l5vBapvw2mog6FXB0MpVyK/8dCX0hxG1r7ZyNoO2zYAI0bFeP1p2bM/6lL7AUWQit4kxYxQR2rvEmN9tIOR8rlWob2LYqj4zEDDKTszA5mgiuHMSA6S9zYvcpAiP8ObE7mioNK6EuHf+5RUjoCyFuWy+Meo5V3/zKuahEAPb9cpA9aw7Ydyo4G1UANmcmLT/BudNOPF2/MRVqRPLU65W5r3Nz1s3bTE5mLtpmwzfYm2aP2JegrVQnvLSa9J9J6AshbjtaF6HT++BiSMRgiOSBnq2xWaysnrkBAGUAbQPQnI93pGKNAgJCi+jQ9zFmv7eAKg0q4eLmzPgN76O1vmXWvy0JCX0hxG1jyZRVHP8tikFfPosq2kyzti4U5eUyY+RZtP5jKOZi4IPCXGjk6Xq1GPRlTzoNbk3K2VTufcY+J75SCnQ22qZRBs9SadO1dvv8+hJClHnLvljDujmbyEp3QPlvxN3TjadePoeH9+VTI5icFPbHdOz/6TT4OYIjq3Hk12kc3/oz3328GIBvP/qRnOjm6ORWF17suvVJ6AshbhvvL36De564kyH3f8CJvbls+uUF3niqMjlZjoD92XsAc+EfAd74/vrUuqsaOxd2o37DyUxcHk+vT7oyqc905n3wA9tXOmFVTVFKkZGcSXZ6Tqm07VqR4R0hxC0vP7eA9fM3M6HX9OJte9Yd4MCGBA5scwdsPNXnPF6+ZmZ8EPbHgQremNWflxsMxtHBh/rNC6nZvBfBHoEc3HQUq9lC5RYLMAVEYDFbeK7Cy3j6lWN+3LQb38hrREJfCHHLe73lu5zce/qybfNHL6Yg2z5pmqu7jZeGJZKXY8DkpJk6rDyuHs4MXTAQL39P2nZtyXejFzPmf00ZMrslNZvB5N9GYy40U87Hg00/bOfkvhiaPNgAT1+P0mjiNSOhL4S4Ze1Z9QO/78nk5L4/Ar9S/XCi98cWBz5AXo6R/g9E4lqDVJz8AAAgAElEQVTOlcQ4fyCFvOwCKtcLZ+TT43m0X3u0Db4fs5hfvt1MzWbVMDk6YHQwAvD12/M5G5XAd2en4xvsfaObeU1J6Ashbik2mw2lFJsWLKZRo3cY8mCdy/aHVAoien/sX46LOuAGQItOVUiKSaHWPdU4vvMkmxZux8PbjYzkTJo+0pCeH3UG4MVaA8hOy2Fh0gxGLHmTlPjUWz7wQW7kCiFucl8P/ZYPnh6PzWbDarHSKagnj/l058Muc9mxxgMPbytgf7wyJKKQ5/rM4e0vYi45g6ZeC3/cvVzwD1U0utdA9SaRpJ1L55MXpjD8h0H0+OBZdvy8l1P7Y3Bxt0+kExoZRHClQKYOmElhXiEV61Tg1bvf4Zd5m2/8RbiGpKcvhLiprZ+/lcTT5zm5P4ZOgx/BaDKQmZKPkyuMez2Sui1rcXTbMboMPE3DltlUrF7IuoVegMbTzwU3j0wObEqmSt1CJq86TqHNlS/fUWSn5WByNlGvVS08vN2Zf+YLjCb7cM65U4l06Ncem9XG8MfGkJ9TwCMvt+PY9hOEVg6idefmpXtR/gN1sz172qhRI7179+7SroYQopTlZubiWs6VzJQsjm47wfDHx/BI3/t5rvc0Du/QfPNxMImxztiscPFFq8DyhdzzUCbLZvpiMTvg7OqMuchM5foVOb4ziif612btt4cpyDXh4ePOZzs+JKC832Xfa7PZeND5OawWKx+ueou8jALqtqqFd4An8VEJBFTwuyknWVNK7dFaN7pqOQl9IcTN5uT+0/Rp8AYPvNiahu3qsW/dAc5GneDApjgq1cwjIdZEXvalwWsP/Yv/dXG38ML7tZky8Dj+5X3JOJ+JxWxB26Bqo0rUurs6fSc8/5fv3ffrIfKy83nv8U8AWBl/AIPXhxhcn7oRzf5PShr6JRreUUq1ByYBRmCG1nr0n/a3ACYCdYFntNaLLmyvD0wFygFWYJTW+vt/0xAhRNmy+cedFOQWEFDBjzPH41n51S8X9mhCKhZw6rArAMqg0LaLnVZF+ap5xJ1wxSugHJOW7SSo/BHWzWvII/2fpmHbujxb/mUAat11eeDHnzhHzJE4PnlhCnmZ9mGjSSvOk5FeHoPBGXC8cY2/Aa4a+kopIzAFaAvEA7uUUku11kcvKXYG6AEM+tPheUA3rXWUUioE2KOUWq21zrgmtRdC3FYK8gsZ8dRYHExG3vtxMD9O+p6BE+P58v1AWndMI6J6Ho6OitQkE+fjHdn9qwfJCSYsFiO+IeWxaSOfrB3AlL592bPBnXe+e42mD9/JovHLCK4ciIubM70+6Vr8fRsXbeeDTuMxOZkwF5pRBk1hnmL5LAcGTjZj8D14hdremkrS028CnNRaRwMopb4DHgWKQ19rHXNhn+3SA7XWJy75+ZxS6jzgD0joCyH+wma1oRRYLFY+6vwBFaoW4OlTiJOrjV8W+VCQ68ek5Sep0TCP4HAz21aV4+DuZvSd/BmPeXenML8IH+f+pCQ4UJBnRBnsQ0DzPviBnIxcVhbOx8Fkj72FY5cw/Y25GE1GzIVmjCYjQ6YkMWu0OxUbtEd59ynNS3HdlCT0Q4G4Sz7HA3f+2y9SSjXB/nfSqX97rBDi9ma1WsnLyuetB0YVL1EYVKGQmOPOvNutEsWTowF92lQjokYeYxZFk5PXipfGjQJg+sFx9l8arj/w6bpjmJ0/xsnF/vjlxK0fYC40Fwc+QO0mccz+7SizJrRi/YIU7n3mblp0qUWLJxejPF9GGdxvWPtvpBvyyKZSKhiYA3TXWtv+Zn8voBdAhQoVbkSVhBCloDC/kMSYZJZNXU3bbi2p1iiS/Jx8hrQbydEdUTi5WAEjKM2pw244Oln5I/A1KI27pwdtO4fiGdKQ9n1HFJ/7j6dw7D10p0u+N7zGH/PtmIvMGB2MVGtgghwzGedOYjD64OlXDoPzfeB83/W8BKWuJKF/Fih/yeewC9tKRClVDlgOvKO13vF3ZbTW04HpYH96p6TnFkLcOhJjztOtcn8CKviRFJvMksmrGLW0E1+8Pou4ky6ApjDfwJtTYvl+sj8xx1yo3TSfvRvtb9J6B1hIP2+idosaPDF4IAbTv++zxv1+lpfqDsTN05Wn33gUgxrK8QO/MGHzMKo3jrzGLb45leSN3F1AFaVURaWUI/AMsLQkJ79Q/idg9sUneoQQZcOpAzH8tnJf8ectP+7E5OxATqZ9YXKUjWFPLLgQ+ACKpu0yaXJvFvc9lgYoajTI5pEeyXz6cxTzdh+lRsMcdizdTZ+Gb5S4Hlpr9v16iJyUvQxp9zpWs5WslGw2/7CTpwZ2Y3HarDIT+FCCnr7W2qKU6g+sxv7I5tda6yNKqRHAbq31UqVUY+zh7g08opR6X2tdC+gEtAB8lVI9Lpyyh9Z6//VojBDi5jH88TEkxSTjHeRFo3Z1ObT5GEX5ZoryzQC4uNnIzzGglL6wqpVmxxpP+t7vwmerotm3tRCr1cDDPQxEVM2nqNBA205pHNvjhrOb05W//AKtNV8Pnc93H/2EyUnRpmMyBYUN6T5qIF7+5a5j629e8nKWEOKaOxedxISXpuJfwY89q9aRmeqIzQZvzurPF4Nnk5GYCYCjiwUHB3isZzLfTgjGwWSjSr08ju12p2ajHCYsPUU+z+PieArlNZ7cbCOnD8ZS6+7qxevWHthwhODKgX95s1ZrzZvtRrLvl0MYjAZsVhsfr3yUO9o9g1K33ww01/TlLCGEuJKdy/fw1dvf0rh9fdZ/txXfYG+O/3aSKg0rMWtnFJuXuTFvUl1Gd/3skqM0kbULiDroSoNWjpw46MrDXY5yZI83x3aDR2B9cH8EV7cXUcres3f3hDrNaxafIT4qgUH3vUfVRpWYvHM0WluI2dGX39Y5smGxC6f2x6KUokPf+3nhw+dwcXO+wVfm5iOhL4T4fyvMLyTjfCa/rdzL6UNn8C/vS3JcKs8NfZLEmPNE7Ynmp+leLJ/rQ9KZzMuO9Qr04v1ln+Pu7cb2ua14pNthhnevRLXGlVlrG83Kr3/hk/5HWTe7CxWqh/DV0Ul/+X4PHzfadm/F+vmb6RzRl2EzfahWYyPLTodyar8fY9YOI6hSIMEVA2/UJbnpyfCOEOL/bcj9I9mz1v7Wqqe/ByZHEyln0/AK9CQjKYOqdxg5ddiMo6MmP/evfcygigFM3DySZ8J6Y3SAyDsqc0frOrTr3ooh7T7gfFxKcdlF57/C0++PcXhzkZnHvXtgcjKRk2G/OVylbj4DJ8SybG4jnv940mXlb3clHd6R+fSFEFeUl51fvBi41prRXT/lrQc+YP33W6nfug4hVYJAQWZyNiln0wDISMoEFFH7rVjNRmZs/h0nFysmJxtdBiVStb79fImnz5OdnoN/eT+sFvh91yl2rznICzVeo3z1ECZt/YAnBzxE9TurFN+81VqTnpSBMijCa4WQm5VXXFeDcx1CGv/G/2Z8XaYC/9+Q4R0hxBX1qjeQ9MQMlmTOxmA0sHHRdiyFFnavPsDCowf5dmQ9++SWf0NrxeMvned8nCNNHmzMkc07eaZ/BqFVavBx73Q6v/MkMYfjSI5LITDCn5T4NNy9XKjbsiaN299BtSaR1GxW7cK5zNgsCQxoNYWj235HGeDiq56PvdKCjoOe/cvNXPFXEvpCiCvyCvAkPTGDqQNmEhy2D0uhpXhfx5p1MBqt/POggY2fvgzgpy/9+SG1J8lnnsUYEkb5O2Jxcn0Xn2AvqjSsRO3mNQgM9+OXuZs5tT+Wod8N4M12I0lLysBgUCREJ9G24ymmvx3LmSgXlEFhNBqxaAv3d3agz4SeGAwu/1AHcSkJfSFEsW9HzWXd3K2M3zQaL39P4k8mkBSTTFGBmaWfr+aPeevtlAKDg8Zq/eu5KtULxyfIi92rD9Cue3MMypX/3fUa9e6tzaif3+LnnHnFZSdsHIHWmod6tSOwgi9FhRYq1AjFaDIyf9SPAPy+y5XE0/Zgr9uiJmN/fQ+bzVb86KYoGQl9IUSxFdOXkBQHLzd4nQdebMmicUsZNfckh3a6M3N0ECYnG+ZC42XHPPZiCr/+FEhqApSvHkpmcjZZqVmEVglm86IdlK8Rhou7O6O7forBaMDD2+1vv1spRdWGFbHZNDGH49BaM3/UjzRtl8GOtV70HN2bQ5uP0fj++lS/swqABP7/gzy9I0QZl5GcycBWw2j1ZBjHdkZzeFsSI2bHMPmtUKw2+GrTCY7udmVAhyrUuzubo7vcMBcpLu3xu3g4U7dlTf73eS8+6z+D7Uvt/4arNKxEOT8P9qw+ULyw1bzYqbh5uuJWzr4YyulDsbh6ujL8sTHEHovHWmQhODKIc1GJhFcvYOj0swTU3YRrudtz1strRV7OEkJcZvHklXwxcBYPv9yWfhNf4Odpa1k54xfuerQRZ44lsHbOaUDx2Itp7FjrQfwpZ3wCzWSnG3j7mUo83vM8Viu8NzOalfN8mf5eGJXrRVCpXgVadLyLpg81BODdhQPpWrk/KfGpRO2JpkP/9iScTKTbiKcJCPNjx897mPradF786HEcXf34rO9Xf6mrpchKsw6NeOyVVoTfVeO2nea4NEhPX4jbnNaa6IOxvHbPUApyC3F2c8JcaMZqsT/60v65PI7sUjS+N5sfpwcA4OZpxlxooMl9mWxf40V41UKmrrP3+D1D21NYYGTS6zZadGxGx9c7XPZ9h7ccY0CLd4s/f58wHZ9Ab6YNnk1uZh6FeYU88ORcAkLzefWhSLIznLBZ7XVxcnXE3duN1LPpLM2ajYu73JwtKenpC1EGpSWmM+rZiXToez8tO97Foc3HWDx5JZsWbi8uU5BbWPxzx35FpCfnYzW7suRr/wtbNeYCAyhFm6dhy0oD2VkebFz5EA0e6IxnUCOmDZ7F8Z0/cy466S+hX7VRZfpO7IG7tyu1m5rx9jfa6/HpCixm+x1fV0c3Vs6tgM2m+Ob4eHpUfQ2AGYcn4OzmRH5OgQT+dSKhL8RtpF+Tt0iJT+XgxqN8OWQuSaeTKedjBhwwOmislsvH4hdOMQG+ABhNNoZ/FUPtprlsWOLDXZ0Xs3ftIRq1+phHelWjWaePsc+WDh7e9uGWP99I/WbYfL4d9SNf7PuESjVS0WnPcmhVDYY84YTF/Meows8z/fELsdCyQxohlX0Z+FUfigrMBEXY/9Lw8ve8fhepjJPQF+IWlp+Tz9mTiUTWr0ifhoNIOZtavM/RIQZwoyDXwJO9kzm6241jey4+OXMxgP/4BWA1K7au9OD0cVce6v8u3mGe3NnOQvOWZ3BxO01mjCNeFccC0LBtPb77eDGdBj96WX3cvezTHp/YfYq8LA9ObPRjz4Y8zEWOePlZyEhxIKhiAJkpWTw39BEe7tkApZxp//ztvVrVzURCX4hbhNViZdeq/dRtWRNXDxdsud8y8on17FqXgZMLFOZrwAYYaPOUfRGSuChXigqNZGcYadAimzNRTuRmG0Dbw95gBJsVHJ0s1LonnPjoPAZ/epIda4dwYGc9eg/dzLzPAog57kzvT+wLjSSdSeZ8XAoe3u4c3X6C6UPm8tJHncnNzCOsqhd+QRlkxg5nxbRwzkRVIS8zj3seSifudEU6v/sE9z9/r8x2WYrkRq4QNyGr1cqE3tOo1jiSR3q3A+D7j5cw46251GtViyp3uJOfuozV832xmA1cfB7Sy9dCbraRkIg8Yk+4c+nLVPXvrUhm0jFOH3Umsk4e0UfdsVlt1L+vNudOJnL+TAreAaC1BW//IizWIGZsTsJmc8CcG4Vz+VWs+OY4E3tP/0t935j9Cgc3HOHZ3pPxD7FgNGrmjAumTe/vOLjxKK27tMDRyXTDrl9ZJBOuCXEL27VyP6u/Xs/0QbNZ8vkqnq/xKl8PnQPYFw2pc8c81v/og8Vs5GKoe/mb6fFWAuYiA3EnXS+cSXFHiyzcvSzc/Vgzurw3hLAqXrR4phs2q41695gYPG4VGeeTCK8ZRkB4ZTJSHHhl6lgmbh0POFFkDqD73Xcx9LEZmIzRmBwdaNahET+mfo2Tiz3IfQI9uf/5e0lOrITN2Bjt0ovnRs4nNDKYB15sLYF/E5HhHSFKmbamgvkg2rElBbmFpCdlMKzDRxiMRgpyC5n/4TQK8zRGBwM2q/1t2Pefr4TNauDSnnxGsiNzxgZRzseMwWglI9k+hHL0Ny/u7dyKbz9awcO92hAflYFPcABPvPYQabGr8fQp5Ok3O1CtUR2GPjKaOx9uQK27q3Fw4yHeaq/o2C+R9EQn9v2SgUlvY0naJEyu9oVMFiR+RW5mHv5hvhdas6y4XZe/tytuFhL6QtxgVquV9fO3Uq9VLZSChaN6sWmJhRpNprN5iZnGbexP2NisVlCQeu7Sf6b24dg/Bz5owioXkJpooveIHCYO9CIg3I/Us2kUFthwMBlJT8yg5dN3cd9zzQmtEkyfBm9w6oCFRo+Mo9vwe8lKzSayQUXOx6bwmFd3hsx9FavVwMpv/Wl4fyXOnjjF1pWQne2Pz4U/JFw9XHD1kEcrbyUypi/EDTRz2HzmXZhAzOBgwGaxYTJZMJsdUAYb2nYxxP8I8+YPZ/BEr2S+GR3M4Z1uxYHvG1hEapL9EUoHR1gQFcCE18PY/MM+AMr5edB7bDdOH4pl+fRfeO2Ll7jv2ebFdTmx5xT9Gg+hfPVQvj46sXj76K6fsmftQb45Pon4E+d4penbPNq/Pd2GdyIrLYewKsHX+zKJ/wd5OUuIUnT2ZAJjekyh6cMNOf5bFIO/7kdORjoLxi7CN8hCaqIjtgtvxJrNRkCjbZfeYvujM9Z1UBIhEUVEHXDBaNTYrACKgDAz3oGOnI12wSfEG+fAcXQaHENQxTAe6NmGcj7ufPXWt8QejSM/O5+kMymXVpGqDSszYsmbBFe6fCnBIXNeLf65epMqLEyaQTlfDwwGA+V8Pa7xlRI3mvT0hbjGrBYr67/fysddP0MZFN5+RYRVsXBwqzOgqH5HDsf3uXHxiRsXN+slSwnah2zcPMxUuyMfiwVOHnLFYFCYixRWC1jMBgxGRcuOTVn/3XZCqwQz8/dP/7Yuz5bvTeq5NLSG8FphzDg04cZcBHHDSU9fiBssam80P89Yy4ov1gGansPO0fyhTLLSjBhN0LddFdCK9JQ//tl1fyOB515Lpl+7ypw87MZDXVN44Z1EhnUN56PvTgPwxfBwfvrSiyf6+vBAlwI2rX6Qe55oysFNRynIM9P04Yb/WKfpB8fRu/4gMlOy6f7e09f7EohbgIS+EP9SRnImr90zjIKcBD5ZdBK/CtU5eyKeN57wIyfTgYu99cAwMwFhZhZN9aewwADaPhZfuXYBSXH2J2vORjuRfM6BT1ecAtdeWPN+Zv8GN5555bz9y0wtaN+nJ1vXzKJGiy6cOWtg6+IfaNi2PlNe+Zrgyv68/9OAf6yrh7c7s6I+s5/KUR6bFBL6QvyjooIijA5GjA72hw+T41P45PnPOXcqgaSYFCKq5xFaMZeE2IMU5Jrw9PW6EPr2m7AfvlwBkxMUFSi8/YuoVDuH6MNuJJ1xpPWzntz1SEM2LdyCwZCIsVxf0GkYnQwE1pvH6T1z2LJiNU7+D+HskoRCsfTz1fgEeRF9IJYZb83lrXk9CfIagk7rhvL97h/bIWEvLiWhL8TfOLbzBB90fIvaTeHXRQYq1ArjzJH4S0postJMxPzuxOr53mxb6UlinDMXe/nKYEHbHEBbWXLyMCgjzi4WPnzlAZRDBANm9OXFWgNIiimi78RxKI/26PSXwZpERK0Azp95gol9Uhj25TwObT5HUmwoSbHJfLTqHU7ui6Hx/fW595mW6NRKYKpTSldJ3IrkRq4o08xFZk4fOsP677awZuYGAiICqN3Uj22Lt3D+7MUe8h+PT17+2b5NKY3WitDKBZw95VJcpGKdCvQb355gv4/4abrmztaZWFzG07BNec5EObFr5T5MziaCIgL4uNtn9B7blXbd7ymeyRLAlr8UW/4Wok+/iNZGqjWKvM5XRNyq5EauEH9Da01CdDRB5QtYOescc0YsJPVsOs7uThTkFJKVmkNY+d3M2RXHlHdC2LaqHA6OmsRYJy4PeyjnW0RWqiP6wuRlyWcvPjNvxMPHg9MHz5ASF4+rLYVFn1dj0ed+rErfxOGVP/L6o/Y1Xr0CPMlMyULbNFmpOZcFPoDBpQMGlw5U9bn+10aUDRL64rZ2eMsxyvm6EFzJC5OTFz9OWsoXr8/FL6QQs7kcmcmFGB1sFOQUXng5ygBKk3jGROzvztRolMvQaXE8f09VzkVf/uZpXtblj1kOmhLAmD6pBFTwZ/qBsRzbEUXdljVRtjZ88HMiBoMDyikd7+BD+IWWIyA8mCp3VCQjOYvBM/vh5Oz4l/oLca3J8I647Wht5fDW35ny6gxO7Y/DycWKwQjVGpXjyRcP4hdkprDQwIie4bTtmE70UWcObvOgfGQhqYkODJ4cS50787BZFM6umnOxJsyFBmKOObFxWRBxpyN44rVHOb33F5ZMO0XDtnVo3aUlbbu2pDC/EIPRIDdPxQ13TYd3lFLtgUnY51CaobUe/af9LYCJQF3gGa31okv2dQeGXvj4gdZ6VsmaIETJndq3jaTTJ1k3/zSHNu3FYlbkZJhwdLZgcoS8HCP7N+Swf0NlHu6ezIFt7qQlOnHmhDO/73fjiV7nWf+TN86uNuo1y6NXq2qYTJpR350hJLwAq89vuEYU0LLTCDA1xuDeFqvlPh54OY5KdcNRyj7E4+TiVMpXQogru2roK6WMwBSgLRAP7FJKLdVaH72k2BmgBzDoT8f6AMOBRtj/Bt5z4dj0a1N9UZbZCneTm+XCjgV9WTHHlSKzjegj7liKHAmtlE/nAUmcjzex9JsA3D0tZKWZcHSy8vMsP0DRbfA5VszzJSvVgfmTLs4no9m+JpT83HKk5xlw8usIrgk4mDzxD4qGtHVQtB3cu2N0MFK5XkQpXgEh/r2S9PSbACe11tEASqnvgEeB4tDXWsdc2Gf707H3A2u11mkX9q8F2gPz/3PNRZmQFJuMT7AXc0Yu4szBlfR+9xBffeBB2nkXug9OJC/HSM1GBbR+0sLxva787+FygOZcjBPThofx+EvnadQqCycXCxkpjhzf64a9/6FZODWAd74birZBQW4Bo56dSHjN8tS8fxoZL/elQeu6eIZ2/6MyDpFoYxVwvr+UroYQ/11JQj8UiLvkczxwZwnP/3fHhpbwWFFGFRYUMeje4eRkpFGQfY6Uc46EVSqkSZssujWO5JWPY3m4ayIPRdTBUmQgLDKfMQtP4uph5s62Gexc64nBoPAJLiT5nInMNCMvv59EjYb5DHg0Ev/wuuxaE0dhnpWslGzG9JiCu7cb8+O+wN3bHavFSlC4P0ER/pfVSxnKofyXl9JVEeLauCme3lFK9QJ6AVSoUKGUayNutITTSRQWFP1fe/ceHUWZ5nH8+3R3ku6kcw/kQsJFIKsJjIAwIqMgiuDiDZV1cJjVEZ1xHdcddY8rimdHQXdBx5ERPLqMO4jH61GHAzOKCAgzgOuAQVBAIMjFEEhCQpJOd+fS6X73jy6wYYMbSdIh9PM5p09XV71V9as6zUOl6u0qVr/6HiUrPmLA+X4O7kjj8htqObzfRfVhJw89X8b5IxrZtCaVBQ/35ZKJDZhQ+Ij90F4nPxk+FGdikBFjPWT3beS2mXH07n8hj07ZzbBxCfT/u30ATJhaw++fLKexoYWsPhkEg+E/Tq+9eyJZfTJPZFpSurA7doVSXa49Rb8cKIj4nG+Na49y4PJT5l13aiNjzCJgEYR777Rz2aoHOrKvkgNffISE6vhw8SqSUz14jtmpr4ln/y4n/oYkUjNaafTGsX1TMsGAkJHdwoYVKXjqbFSWxQHCq89kM3pSPReNE5Y8k079Uejdvx+ffHiIUVc5mDClhNeercbpHsygYb1wuQ3BUDK5hWOYv/EBKvdXMWx8MS63iyunX6a9bVTMaE/R3wwMFpEBhIv4NOAn7Vz+SuA/RCTd+jwReOR7p1Q9Vt3RehJcPr5Y+TifLNuNp9bO1Htq6Du4mdmrimltzeLOWYf5ZEU8/gYHGdkt7NwcfixTWakTETAG3nkhh2X/HSQQsHHeEC/eeid3PVZHdvEc/N4XKVnr5/Hl93Bkn4/8zGmETDIB23U8t346/S7Ix5iniJM4Rt4QznXekG//otSCr2JJu/rpi8hkwl0y7cAfjDFPichs4DNjzHIRGQUsBdKBJqDCGFNszTsDeNRa1FPGmMXftS7tp99zNTc24znm5bOVW/jLW69TX12FhAzJ6a3s255Io9/O0j3bqfgmDptN+Pm4wWQXBHjilQOIDWZNH0CT30aCM0R1RTxjrz+G35vMhWOCfFXixOYcyda1eygcVciji0fgar0PEu+A+EsgUIK470fEjmneCPZsxKG3LFCxo7399PXHWeqMeet8HNp7hG0f/5k9/7OM4lE+vipxs25pBiA4E4P840MV/H52HjaB4ou93PtkOS/+Oo9tG1JITgtw37xDuBJDpGW2suljN5+uSqG2KoEhY8ez7u2NTJt5Ix+/sZ6GWh9Ljy3Gbv/2cdumdR/YCxDRI3WltOirTmeMwbR8yQeL5vL63AZqq+NwJYXw1tvBhB/mDZy4ARlgPRXKzqAfeJk8vYaU9BCL5uRSUxHHzXdXMeORKiTiljYPTxvNV5uDzPnTTFpbWhk6tgiAUDCkD+BW6jvoDddUhx3YfpCdG95lxcuruGPmYWwOG6/M7cWOTamkZNhxukJ4644fZYd7wfxgTANTZlSzfEkWwy9rYMncXERC2O0hFs/NY0CRn0k/ruXWBwuw4wH7QDAJ4JqCJN3AM+vSTx9IKdVhWvQVEO426a3+hOUL/ot1f3Rid4DTHaTmsJOLxgeJS7BRPMpPS8u3X5krbqpjYHETCx7JJzMUv44AAApCSURBVNgqJKW0UlvloOqwg63rU9i2MRkTCh/G7/8qk7TeLkK2Yibc/TMc2YNO3LpAKRU9WvRjUEtzgLVvriM95R0IfM66pU4GDQ0wZmI9nuo8AoEkmvw2fJ44RAzDfuRj9p39yO0XoHRrEpdcXYvLHeSmXxwlr3+AN5/vTWVZAj5PHO70XN5/YzC9+jZTNLqQq24bS98L8skdkN3dm62UQov+OcsYQygUJNAcxO+po7HyN7zyRAl/WZ6CMVB0USNlX7vIyc9k2KWNTLnzGAAXT/DyyYcZHH9gSJ+BTRw5GE+fgX4O7kokwRXCmeTmp/fvoVfhXbTYx3Dn00Gafc0kJju5bOolegSv1FlMi/45xOfxU1/t4Z3fvMbAgW+xsySJrOwAGz7IoKw0gbj4NGw2G1PurOIXv67gjh+dT+mXbirKXFx4qYdR430UFDYCARJTQjT57FQfiWPDB3kMnzCCKQ+M4fJbxmCMAeNDbG4Axv+4e7dbKdV+WvR7sFAoxLEjJbw37yH+usxNlfWM1px+LSRem8g9T1SysySRN3/nQmyGQIsNsRnEDtUVDkwwRN6AJiZNq2b31ngO7IojqfctLN5SSa+Bt7LhTz5GTbqQlMyUk9YrIiDu7tlopVSHaNHvIYwxVH1zlMeun03NoYM0+u0MHelj55ZkQsFMAi0AwsKVe/jVNYVM+IdakpJDCHD1rVX4vHbGXefB7w+yeW0KK17vzYO/a6D/BXZ2bhnFwDH/TlqvlJPuB39le393rZTqMbSf/lmqruoQL9w/n7y8v1K6LZniH/rweew4Ew1vzM8hGLBz/DF9AHHxQQItdp5bXkqwFV77bS9qq+PJKWjmgWfLqDychc35U1L63EjewJxu3TalVOfTfvo9iNfj4405L1B4/mIGFRuS00IkJoGvqj9rNmRTecjJ5jXp3Df3EAtmFmCzhwBDfEIrqVlBhlzsZegYD5+vTWP+v+WQ6E7i2ntnkF84iPMv7odIAplD9OKqUkqLftSFgkF2rJ3FxnfXkJZtCDQ72LQ6nbpqO5e9FI+3HnL6NmKzwfDLvOwsSSQ5rRVvvZ3aahsXjmngiptqqCi3Uzyqidy+Qdz58/D6irnm/gJsNlt3b6JS6iymRb+LrV1yBxV7tnGwNIl751SSmALS5OKLT/uw8MO9fL4+iVefDl8UdThCZOW1EmiB+ATIyPEzYqwHu90QCkF1/bXc9PA4Rk8uxmZPO2k9Gd2xcUqpHkeLficwxlC1fwf7Pr2Zv32Uzv5dqdQcicdT6+DhBQe58ec+phSexxU3+hg53kvRyEa89Q52b3XRd3AT0/6lgk9XJfPsv+byz/95AJs4+ObgFEZefy9X3q0PGlNKdR4t+t9Da6AVCfmR2ul46ncTHw8JzvC0TCdkjYfii+q4dXgfWprCp1k2rkhl6Gg/Ca4gq99NZ8Q4L8eqYOovy6g5ImxcPZ5rfjWLGc9lg/GAJCLipKgbt1Mpde7Son8aoUADgcO34G/8miQ3iIRfSLjPTErqye2PP+zDnRriyqnHWP/nFIaO9nLdz45SfhBeXLOTeu94bBm/JTN7CNcPC98i+NKTFqInaZRSXSumi74xBlP5B2Bem9Md8ZCa0OYka/6Th/dshb07nEx/sJxbHiggrWAB7qxvn9CU10m5lVLqTMVM0Q9VzAT++L3mibyFTGSBb26CRh+kZwEUQvLdiGsyRZPtFE3ujLRKKdU1YqLohyqGAf4zmjcQgGAQnM57IHUUJIwm0eYgsXMjKqVUVMRE0f9eBT95Hbakb0/EfMfZHaWU6nFioujbcvYQqiiMGDMWW87L3ZZHKaW6S0wUfQgXfqWUinX6m32llIohWvSVUiqGaNFXSqkYokVfKaViiBZ9pZSKIVr0lVIqhmjRV0qpGKJFXymlYogWfaWUiiFa9JVSKoZo0VdKqRiiRV8ppWKImMing5wFROQocDAKq8oCqqOwnq7QU7Nr7ujS3NHV3bn7GWN6/X+NzrqiHy0i8pkxZmR35zgTPTW75o4uzR1dPSW3nt5RSqkYokVfKaViSCwX/UXdHaADemp2zR1dmju6ekTumD2nr5RSsSiWj/SVUirmnNNFX0QyRGSViJRa7+mnaXe71aZURG5vY/pyEdne9YlPrK9DuUXkQxHZJiI7ROQlEbH3hOwikigi74vILiv73J6Q2xr/lIiUiYg3SnmvFpHdIrJXRGa2MT1BRN62pv9NRPpHTHvEGr9bRCZFI29Hc4tIpoisFRGviCyMZuYO5r5KREpE5Evr/YpoZ/8/jDHn7At4GphpDc8E5rXRJgPYZ72nW8PpEdNvAt4AtveU3ECK9S7Ae8C0npAdSATGW23igfXA35/tua1po4FcwBuFrHbga+A8az9tA4pOafNL4CVreBrwtjVcZLVPAAZYy7FHaR93JHcScCnwT8DCaH2fOyH3cCDPGh4ClEcze1uvc/pIH7gBWGINLwGmtNFmErDKGHPMGFMLrAKuBhARN/Ag8GQUskbqUG5jjMdq4yD8JY3mhZszzm6M8Rtj1gIYY1qALUB+FDJDx/f5p8aYI1FJCj8E9hpj9ln76S3C+SNFbs+7wJUiItb4t4wxzcaY/cBea3lndW5jjM8YswFoilLWSB3J/bkx5rA1fgfgEpGEqKQ+jXO96GdH/EOsALLbaNMHKIv4fMgaBzAHeBbwd1nCtnU0NyKyEqgCGgh/CaOlw9kBRCQNuA5Y0xUh29ApuaOkPTlOtDHGtAL1QGY75+0qHcndnTor983AFmNMcxflbBdHd668M4jIaiCnjUmzIj8YY4yItPuIV0SGAQONMQ9Eng/tLF2VO2K+SSLiBF4HriB8VNopujq7iDiAN4HnjTH7zixlm8vt0txKnY6IFAPzgIndnaXHF31jzITTTRORShHJNcYcEZFcwke+pyoHLo/4nA+sAy4BRorIAcL7qbeIrDPGXE4n6MLcketoEpFlhP/07LSiH4Xsi4BSY8z8Toh7QjT2eZSUAwWn5Cg/TZtD1n+iqUBNO+ftKh3J3Z06lFtE8oGlwG3GmK+7Pu53O9dP7ywHjvewuB1Y1kablcBEEUm3emxMBFYaY140xuQZY/oTvoC0p7MKfjuccW4RcVtF6/gR8zXArihkPu6MswOIyJOE/8HcH4WskTqUO8o2A4NFZICIxBO+cLj8lDaR2zMV+NiEryYuB6ZZvU0GAIOBTT0gd3c649zWacr3CXcS2Bi1xN+lu68kd+WL8Dm1NUApsBrIsMaPBF6OaDeD8AWtvcAdbSynP9HtvXPGuQmfi94MfAFsBxYAjh6SPZ/wReevgK3W666zPbc1/mnC53pD1vvjXZx3MrCHcK+SWda42cD11rATeMfKuQk4L2LeWdZ8u4lS76hOyn0AOAZ4rX1cdLbnBh4DfBHf561A72ju81Nf+otcpZSKIef66R2llFIRtOgrpVQM0aKvlFIxRIu+UkrFEC36SikVQ7ToK6VUDNGir5RSMUSLvlJKxZD/BcSX1ssZlqkVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data_embedding[:,0], data_embedding[:,1], c=y_predicted, s=1, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
