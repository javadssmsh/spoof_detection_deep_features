{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "import numpy as np\n",
    "# import librosa as lb\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import to_categorical,Sequence\n",
    "import pandas as pd\n",
    "import math\n",
    "import sincnet\n",
    "# from tensorflow import set_random_seed\n",
    "from keras import models, layers\n",
    "import numpy as np\n",
    "import sincnet\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import MaxPooling1D,MaxPooling2D, Conv1D, LeakyReLU, BatchNormalization, Dense, Flatten\n",
    "from keras.layers import InputLayer, Input\n",
    "from keras.models import Model\n",
    "# from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pywt\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "import tensorflow.contrib.slim as slim\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    Suppose `samples` is an array [[audio1,label1], [audio2,label2],...].\n",
    "    \"\"\"\n",
    "    total_batches = int(data.shape[0]/batch_size)\n",
    "    for i in range(total_batches):\n",
    "        X_train,y_train = create_batches(data, labels, batch_size,i)\n",
    "        yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(data,labels,batch_size,batch_number):\n",
    "    wlen = 3200\n",
    "    fact_amp = 0.2\n",
    "    # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n",
    "    sig_batch=np.zeros([batch_size,wlen])\n",
    "    lab_batch=[]\n",
    "    if batch_number == 0:\n",
    "        signal_id_arr=np.array([s for s in range(0,batch_size)])\n",
    "    else:\n",
    "        offset = (batch_number*batch_size) \n",
    "        signal_id_arr=np.array([s for s in range(offset,offset+batch_size)])\n",
    "    rand_amp_arr = np.random.uniform(1.0-fact_amp,1+fact_amp,batch_size)\n",
    "    for i in range(batch_size): \n",
    "#         print(i)\n",
    "        signal = data[signal_id_arr[i]]\n",
    "        # accesing to a random chunk\n",
    "        signal_len=signal.shape[0]\n",
    "        signal_beg=np.random.randint(signal_len-wlen-1) #randint(0, snt_len-2*wlen-1)\n",
    "        signal_end=signal_beg+wlen\n",
    "        sig_batch[i,:]=signal[signal_beg:signal_end]*rand_amp_arr[i]\n",
    "        y=labels.iloc[signal_id_arr[i],-1]\n",
    "        lab_batch.append(y)\n",
    "    a, b = np.shape(sig_batch)\n",
    "    sig_batch = sig_batch.reshape((a, b, 1))\n",
    "    return sig_batch, to_categorical(np.array(lab_batch),num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_conv_block(X,in_channels,out_channels,stage,block,dilation=1):\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = BatchNormalization(name=bn_name_base+'a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv1D(in_channels, 3, padding='valid',use_bias = False, name= conv_name_base+'a')(X)\n",
    "    X = BatchNormalization(name=bn_name_base+'b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv1D(in_channels, 3, padding='valid',use_bias = False, name= conv_name_base+'b')(X)\n",
    "    print(X.shape)\n",
    "    paddings = tf.constant([[0, 0],   # the batch size dimension\n",
    "                          [2, 2],   # top and bottom of image\n",
    "                          [0, 0]])  # the channels dimension\n",
    "    X = Lambda(lambda x: tf.pad(x, paddings, mode='CONSTANT',\n",
    "                        constant_values=0.0))(X)\n",
    "    X = concatenate([X , X_shortcut])\n",
    "    X = BatchNormalization(name = bn_name_base+'c')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv1D(out_channels, 3, padding='valid',use_bias = False, dilation_rate = dilation, name = conv_name_base+'c')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "input_shape = None,3200,1\n",
    "\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, shape=input_shape, name= 'the_input')\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "sinc = sincnet.SincConv1D(64, 251, 16000)(inputs)\n",
    "sinc_pool = MaxPooling1D(pool_size=3,name = 'sinc_pool')(sinc)\n",
    "sinc_layer_norm = sincnet.LayerNorm(name = 'sinc_layer_norm')(sinc_pool)\n",
    "sinc_relu = LeakyReLU(alpha=0.2, name = 'sinc_relu')(sinc_layer_norm)\n",
    "\n",
    "sinc_conv = Conv1D(64, 5, strides=2, padding='valid')(sinc_relu)\n",
    "sinc_pool_1 = MaxPooling1D(pool_size=3,name = 'sinc_pool_1')(sinc_conv)\n",
    "sinc_layer_norm_1 = sincnet.LayerNorm(name = 'sinc_layer_norm_1')(sinc_pool_1)\n",
    "sinc_relu_1 = LeakyReLU(alpha=0.2, name = 'sinc_relu_1')(sinc_layer_norm_1)\n",
    " \n",
    "\n",
    "sinc_conv_1 = Conv1D(64, 5, strides=2, padding='valid')(sinc_relu_1)\n",
    "sinc_pool_2 = MaxPooling1D(pool_size=3,name = 'sinc_pool_1')(sinc_conv_1)\n",
    "\n",
    "sinc_layer_norm_2= sincnet.LayerNorm(name = 'sinc_layer_norm_1')(sinc_pool_2)\n",
    "sinc_relu_2= LeakyReLU(alpha=0.2, name = 'sinc_relu_1')(sinc_layer_norm_2)\n",
    "flat = Flatten()(sinc_relu_2)\n",
    "#concate level one and level two decomposition\n",
    "# concate_level_2 = concatenate([relu_1_2,sinc_relu_1])\n",
    "# print(concate_level_2.shape)\n",
    "# res_conv_1 = res_conv_block(sinc_relu_1, 128, 16, 1, 'a', 4)\n",
    "# res_conv_2 = res_conv_block(res_conv_1, 16, 8, 2, 'a', 8)\n",
    "# res_conv_3 = res_conv_block(res_conv_2, 8, 4, 3, 'a', 16)\n",
    "# res_conv_4 = res_conv_block(res_conv_3, 4, 2, 4, 'a', 32)\n",
    "# res_conv_5 = res_conv_block(res_conv_4, 2, 1, 5, 'a', 64)\n",
    "\n",
    "# res_norm = BatchNormalization(name='res_norm')(res_conv_5)\n",
    "# res_relu = Activation('relu')(res_norm)\n",
    "\n",
    "\n",
    "# pool_5_1 = AveragePooling1D(pool_size=3, padding='same', name='avg_pool_5_1')(sinc_relu_2)\n",
    "# flat_5_1 = Flatten(name='flat_5_1')(pool_5_1) \n",
    "\n",
    "fc_5 = Dense(2048, name='fc_5')(flat)\n",
    "norm_5 = BatchNormalization(momentum=0.05, epsilon=1e-5)(fc_5)\n",
    "relu_5 =  LeakyReLU(alpha=0.2)(norm_5)\n",
    "drop_5 = Dropout(0.5, name='drop_5')(relu_5)\n",
    "\n",
    "fc_6 = Dense(2048, name='fc_6')(drop_5)\n",
    "norm_6 = BatchNormalization(momentum=0.05, epsilon=1e-5)(fc_6)\n",
    "relu_6 =  LeakyReLU(alpha=0.2)(norm_6)\n",
    "drop_6 = Dropout(0.5, name='drop_6')(relu_6)\n",
    "\n",
    "fc_7= Dense(2048, name='fc_6')(drop_6)\n",
    "norm_7= BatchNormalization(momentum=0.05, epsilon=1e-5)(fc_7)\n",
    "relu_7=  LeakyReLU(alpha=0.2)(norm_7)\n",
    "drop_7= Dropout(0.5, name='drop_6')(relu_7)                                                        \n",
    "\n",
    "                                                        \n",
    "output = Dense(2, activation=tf.nn.softmax)(drop_7)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/rohita/rohit/spoof/npy_data_asvspoof/Sincnet/equal_human_spoof'\n",
    "saver = tf.train.Saver()\n",
    "# save_path = saver.save(sess, model_path)\n",
    "with sess.as_default():\n",
    "    latest = tf.train.latest_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohita/rohit/spoof/npy_data_asvspoof/Sincnet/equal_human_spoof/model.ckpt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev.npy\",allow_pickle=True)\n",
    "with open(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_df.pkl\", 'rb') as pickle_file:\n",
    "    y = pickle.load(pickle_file)\n",
    "\n",
    "X= np.array([s[0] for s in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24843,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "batch_size = 1\n",
    "scores = []\n",
    "total_batch = int(X.shape[0]/batch_size)\n",
    "gen = generator(X, y, batch_size)\n",
    "with sess.as_default():\n",
    "    sess.run(init_op)\n",
    "    for i in range(total_batch):\n",
    "        X_batch, y_batch = next(gen)\n",
    "        if i%100==0 | i ==0:\n",
    "            print(i)\n",
    "        score = (sess.run(output,feed_dict={inputs: X_batch, tf.keras.backend.learning_phase(): 0}))\n",
    "#         print(score.shape)\n",
    "        scores.append(score)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array(scores)\n",
    "scores = scores.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['scores_1'] = scores[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['scores_2'] = scores[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>system_id</th>\n",
       "      <th>label</th>\n",
       "      <th>scores_1</th>\n",
       "      <th>scores_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LA_0071</td>\n",
       "      <td>LA_D_9616032</td>\n",
       "      <td>A05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648249</td>\n",
       "      <td>0.351751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LA_0071</td>\n",
       "      <td>LA_D_4264656</td>\n",
       "      <td>A02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633547</td>\n",
       "      <td>0.366453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LA_0073</td>\n",
       "      <td>LA_D_6273410</td>\n",
       "      <td>A04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.475878</td>\n",
       "      <td>0.524122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LA_0074</td>\n",
       "      <td>LA_D_6947992</td>\n",
       "      <td>A05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524474</td>\n",
       "      <td>0.475526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LA_0072</td>\n",
       "      <td>LA_D_9410329</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533137</td>\n",
       "      <td>0.466863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LA_0077</td>\n",
       "      <td>LA_D_3624723</td>\n",
       "      <td>A05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638721</td>\n",
       "      <td>0.361279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LA_0070</td>\n",
       "      <td>LA_D_2591082</td>\n",
       "      <td>A02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.613276</td>\n",
       "      <td>0.386724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LA_0075</td>\n",
       "      <td>LA_D_5223993</td>\n",
       "      <td>A03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518717</td>\n",
       "      <td>0.481283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LA_0102</td>\n",
       "      <td>LA_D_7153183</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479007</td>\n",
       "      <td>0.520993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LA_0072</td>\n",
       "      <td>LA_D_3428449</td>\n",
       "      <td>A01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504549</td>\n",
       "      <td>0.495451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LA_0069</td>\n",
       "      <td>LA_D_6166623</td>\n",
       "      <td>A02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524624</td>\n",
       "      <td>0.475376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LA_0076</td>\n",
       "      <td>LA_D_2886143</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533089</td>\n",
       "      <td>0.466911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LA_0075</td>\n",
       "      <td>LA_D_2662277</td>\n",
       "      <td>A01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544978</td>\n",
       "      <td>0.455021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LA_0071</td>\n",
       "      <td>LA_D_9097473</td>\n",
       "      <td>A04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514945</td>\n",
       "      <td>0.485055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LA_0071</td>\n",
       "      <td>LA_D_5332359</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513303</td>\n",
       "      <td>0.486697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LA_0073</td>\n",
       "      <td>LA_D_1020087</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531028</td>\n",
       "      <td>0.468972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LA_0072</td>\n",
       "      <td>LA_D_2105580</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0.621537</td>\n",
       "      <td>0.378463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LA_0071</td>\n",
       "      <td>LA_D_3589733</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543919</td>\n",
       "      <td>0.456081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LA_0072</td>\n",
       "      <td>LA_D_2234125</td>\n",
       "      <td>A02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509575</td>\n",
       "      <td>0.490424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LA_0077</td>\n",
       "      <td>LA_D_7060794</td>\n",
       "      <td>A03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588116</td>\n",
       "      <td>0.411884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LA_0077</td>\n",
       "      <td>LA_D_8481763</td>\n",
       "      <td>A02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481825</td>\n",
       "      <td>0.518175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LA_0075</td>\n",
       "      <td>LA_D_7063900</td>\n",
       "      <td>A04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433453</td>\n",
       "      <td>0.566547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LA_0069</td>\n",
       "      <td>LA_D_2430765</td>\n",
       "      <td>A03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514655</td>\n",
       "      <td>0.485345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LA_0072</td>\n",
       "      <td>LA_D_1024541</td>\n",
       "      <td>A04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.615952</td>\n",
       "      <td>0.384048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LA_0104</td>\n",
       "      <td>LA_D_2722562</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508018</td>\n",
       "      <td>0.491982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LA_0073</td>\n",
       "      <td>LA_D_6536882</td>\n",
       "      <td>A02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514880</td>\n",
       "      <td>0.485120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LA_0074</td>\n",
       "      <td>LA_D_6516523</td>\n",
       "      <td>A03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729625</td>\n",
       "      <td>0.270375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LA_0077</td>\n",
       "      <td>LA_D_1997028</td>\n",
       "      <td>A01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.557952</td>\n",
       "      <td>0.442048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LA_0106</td>\n",
       "      <td>LA_D_2817557</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0.551641</td>\n",
       "      <td>0.448359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LA_0073</td>\n",
       "      <td>LA_D_2819105</td>\n",
       "      <td>A01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561093</td>\n",
       "      <td>0.438907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24813</th>\n",
       "      <td>LA_0075</td>\n",
       "      <td>LA_D_9156289</td>\n",
       "      <td>A03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546087</td>\n",
       "      <td>0.453913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24814</th>\n",
       "      <td>LA_0069</td>\n",
       "      <td>LA_D_5772395</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.557726</td>\n",
       "      <td>0.442274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24815</th>\n",
       "      <td>LA_0070</td>\n",
       "      <td>LA_D_5027960</td>\n",
       "      <td>A05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.517576</td>\n",
       "      <td>0.482424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24816</th>\n",
       "      <td>LA_0071</td>\n",
       "      <td>LA_D_3331528</td>\n",
       "      <td>A04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.616999</td>\n",
       "      <td>0.383001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817</th>\n",
       "      <td>LA_0071</td>\n",
       "      <td>LA_D_1948572</td>\n",
       "      <td>A05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593316</td>\n",
       "      <td>0.406684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24818</th>\n",
       "      <td>LA_0077</td>\n",
       "      <td>LA_D_5271365</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520312</td>\n",
       "      <td>0.479689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24819</th>\n",
       "      <td>LA_0076</td>\n",
       "      <td>LA_D_8829502</td>\n",
       "      <td>A05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538629</td>\n",
       "      <td>0.461371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24820</th>\n",
       "      <td>LA_0074</td>\n",
       "      <td>LA_D_3713729</td>\n",
       "      <td>A01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544074</td>\n",
       "      <td>0.455926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24821</th>\n",
       "      <td>LA_0072</td>\n",
       "      <td>LA_D_6270876</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.598436</td>\n",
       "      <td>0.401564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24822</th>\n",
       "      <td>LA_0074</td>\n",
       "      <td>LA_D_4076908</td>\n",
       "      <td>A01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472804</td>\n",
       "      <td>0.527196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24823</th>\n",
       "      <td>LA_0072</td>\n",
       "      <td>LA_D_7205018</td>\n",
       "      <td>A03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.478034</td>\n",
       "      <td>0.521966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24824</th>\n",
       "      <td>LA_0076</td>\n",
       "      <td>LA_D_9793796</td>\n",
       "      <td>A04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520760</td>\n",
       "      <td>0.479240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24825</th>\n",
       "      <td>LA_0070</td>\n",
       "      <td>LA_D_1110836</td>\n",
       "      <td>A01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594551</td>\n",
       "      <td>0.405449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24826</th>\n",
       "      <td>LA_0069</td>\n",
       "      <td>LA_D_9502387</td>\n",
       "      <td>A02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481344</td>\n",
       "      <td>0.518656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24827</th>\n",
       "      <td>LA_0072</td>\n",
       "      <td>LA_D_5331264</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576427</td>\n",
       "      <td>0.423573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24828</th>\n",
       "      <td>LA_0078</td>\n",
       "      <td>LA_D_3109995</td>\n",
       "      <td>A04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551720</td>\n",
       "      <td>0.448280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24829</th>\n",
       "      <td>LA_0070</td>\n",
       "      <td>LA_D_2112409</td>\n",
       "      <td>A04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.669570</td>\n",
       "      <td>0.330430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24830</th>\n",
       "      <td>LA_0072</td>\n",
       "      <td>LA_D_3823574</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.494279</td>\n",
       "      <td>0.505721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24831</th>\n",
       "      <td>LA_0069</td>\n",
       "      <td>LA_D_8385680</td>\n",
       "      <td>A03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586198</td>\n",
       "      <td>0.413802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24832</th>\n",
       "      <td>LA_0078</td>\n",
       "      <td>LA_D_1652144</td>\n",
       "      <td>A01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461628</td>\n",
       "      <td>0.538372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24833</th>\n",
       "      <td>LA_0074</td>\n",
       "      <td>LA_D_5781241</td>\n",
       "      <td>A01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540654</td>\n",
       "      <td>0.459346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24834</th>\n",
       "      <td>LA_0070</td>\n",
       "      <td>LA_D_1435765</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524757</td>\n",
       "      <td>0.475243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24835</th>\n",
       "      <td>LA_0078</td>\n",
       "      <td>LA_D_4963222</td>\n",
       "      <td>A01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.577946</td>\n",
       "      <td>0.422054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24836</th>\n",
       "      <td>LA_0072</td>\n",
       "      <td>LA_D_7880514</td>\n",
       "      <td>A02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519934</td>\n",
       "      <td>0.480066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24837</th>\n",
       "      <td>LA_0077</td>\n",
       "      <td>LA_D_5440591</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602830</td>\n",
       "      <td>0.397170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24838</th>\n",
       "      <td>LA_0078</td>\n",
       "      <td>LA_D_6134944</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456835</td>\n",
       "      <td>0.543165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24839</th>\n",
       "      <td>LA_0072</td>\n",
       "      <td>LA_D_8128338</td>\n",
       "      <td>A06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.742516</td>\n",
       "      <td>0.257484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24840</th>\n",
       "      <td>LA_0075</td>\n",
       "      <td>LA_D_2780356</td>\n",
       "      <td>A05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455360</td>\n",
       "      <td>0.544640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24841</th>\n",
       "      <td>LA_0074</td>\n",
       "      <td>LA_D_9498483</td>\n",
       "      <td>A04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508837</td>\n",
       "      <td>0.491163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24842</th>\n",
       "      <td>LA_0070</td>\n",
       "      <td>LA_D_6265671</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0.532882</td>\n",
       "      <td>0.467118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24843 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      speaker_id       file_id system_id  label  scores_1  scores_2\n",
       "0        LA_0071  LA_D_9616032       A05      1  0.648249  0.351751\n",
       "1        LA_0071  LA_D_4264656       A02      1  0.633547  0.366453\n",
       "2        LA_0073  LA_D_6273410       A04      1  0.475878  0.524122\n",
       "3        LA_0074  LA_D_6947992       A05      1  0.524474  0.475526\n",
       "4        LA_0072  LA_D_9410329       A06      1  0.533137  0.466863\n",
       "5        LA_0077  LA_D_3624723       A05      1  0.638721  0.361279\n",
       "6        LA_0070  LA_D_2591082       A02      1  0.613276  0.386724\n",
       "7        LA_0075  LA_D_5223993       A03      1  0.518717  0.481283\n",
       "8        LA_0102  LA_D_7153183         -      0  0.479007  0.520993\n",
       "9        LA_0072  LA_D_3428449       A01      1  0.504549  0.495451\n",
       "10       LA_0069  LA_D_6166623       A02      1  0.524624  0.475376\n",
       "11       LA_0076  LA_D_2886143       A06      1  0.533089  0.466911\n",
       "12       LA_0075  LA_D_2662277       A01      1  0.544978  0.455021\n",
       "13       LA_0071  LA_D_9097473       A04      1  0.514945  0.485055\n",
       "14       LA_0071  LA_D_5332359         -      0  0.513303  0.486697\n",
       "15       LA_0073  LA_D_1020087       A06      1  0.531028  0.468972\n",
       "16       LA_0072  LA_D_2105580         -      0  0.621537  0.378463\n",
       "17       LA_0071  LA_D_3589733       A06      1  0.543919  0.456081\n",
       "18       LA_0072  LA_D_2234125       A02      1  0.509575  0.490424\n",
       "19       LA_0077  LA_D_7060794       A03      1  0.588116  0.411884\n",
       "20       LA_0077  LA_D_8481763       A02      1  0.481825  0.518175\n",
       "21       LA_0075  LA_D_7063900       A04      1  0.433453  0.566547\n",
       "22       LA_0069  LA_D_2430765       A03      1  0.514655  0.485345\n",
       "23       LA_0072  LA_D_1024541       A04      1  0.615952  0.384048\n",
       "24       LA_0104  LA_D_2722562         -      0  0.508018  0.491982\n",
       "25       LA_0073  LA_D_6536882       A02      1  0.514880  0.485120\n",
       "26       LA_0074  LA_D_6516523       A03      1  0.729625  0.270375\n",
       "27       LA_0077  LA_D_1997028       A01      1  0.557952  0.442048\n",
       "28       LA_0106  LA_D_2817557         -      0  0.551641  0.448359\n",
       "29       LA_0073  LA_D_2819105       A01      1  0.561093  0.438907\n",
       "...          ...           ...       ...    ...       ...       ...\n",
       "24813    LA_0075  LA_D_9156289       A03      1  0.546087  0.453913\n",
       "24814    LA_0069  LA_D_5772395       A06      1  0.557726  0.442274\n",
       "24815    LA_0070  LA_D_5027960       A05      1  0.517576  0.482424\n",
       "24816    LA_0071  LA_D_3331528       A04      1  0.616999  0.383001\n",
       "24817    LA_0071  LA_D_1948572       A05      1  0.593316  0.406684\n",
       "24818    LA_0077  LA_D_5271365       A06      1  0.520312  0.479689\n",
       "24819    LA_0076  LA_D_8829502       A05      1  0.538629  0.461371\n",
       "24820    LA_0074  LA_D_3713729       A01      1  0.544074  0.455926\n",
       "24821    LA_0072  LA_D_6270876       A06      1  0.598436  0.401564\n",
       "24822    LA_0074  LA_D_4076908       A01      1  0.472804  0.527196\n",
       "24823    LA_0072  LA_D_7205018       A03      1  0.478034  0.521966\n",
       "24824    LA_0076  LA_D_9793796       A04      1  0.520760  0.479240\n",
       "24825    LA_0070  LA_D_1110836       A01      1  0.594551  0.405449\n",
       "24826    LA_0069  LA_D_9502387       A02      1  0.481344  0.518656\n",
       "24827    LA_0072  LA_D_5331264         -      0  0.576427  0.423573\n",
       "24828    LA_0078  LA_D_3109995       A04      1  0.551720  0.448280\n",
       "24829    LA_0070  LA_D_2112409       A04      1  0.669570  0.330430\n",
       "24830    LA_0072  LA_D_3823574       A06      1  0.494279  0.505721\n",
       "24831    LA_0069  LA_D_8385680       A03      1  0.586198  0.413802\n",
       "24832    LA_0078  LA_D_1652144       A01      1  0.461628  0.538372\n",
       "24833    LA_0074  LA_D_5781241       A01      1  0.540654  0.459346\n",
       "24834    LA_0070  LA_D_1435765       A06      1  0.524757  0.475243\n",
       "24835    LA_0078  LA_D_4963222       A01      1  0.577946  0.422054\n",
       "24836    LA_0072  LA_D_7880514       A02      1  0.519934  0.480066\n",
       "24837    LA_0077  LA_D_5440591       A06      1  0.602830  0.397170\n",
       "24838    LA_0078  LA_D_6134944       A06      1  0.456835  0.543165\n",
       "24839    LA_0072  LA_D_8128338       A06      1  0.742516  0.257484\n",
       "24840    LA_0075  LA_D_2780356       A05      1  0.455360  0.544640\n",
       "24841    LA_0074  LA_D_9498483       A04      1  0.508837  0.491163\n",
       "24842    LA_0070  LA_D_6265671         -      0  0.532882  0.467118\n",
       "\n",
       "[24843 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"/home/rohita/rohit/spoof/npy_data_asvspoof/dev_scores.txt\",\"w\")\n",
    "\n",
    "for i in range(y.shape[0]):\n",
    "    if y.iloc[i,2] == '-':\n",
    "        L = y.iloc[i,1] + \" \" + y.iloc[i,2] + \" bonafide\" + \" \" + str(y.iloc[i,-2] - y.iloc[i,-1]) + '\\n'\n",
    "    else:\n",
    "        L = y.iloc[i,1] + \" \" + y.iloc[i,2] + \" spoof\" + \" \" + str(y.iloc[i,-2] - y.iloc[i,-1]) + '\\n'\n",
    "    file1.writelines(L) \n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2579, 1: 3800}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train.iloc[:,3], return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker_id         LA_0088\n",
       "file_id       LA_T_1241016\n",
       "system_id                0\n",
       "label                    0\n",
       "Name: 9345, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.iloc[1888,:]#,y_train.iloc[2176,:],y_train.iloc[23213,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker_id         LA_0086\n",
      "file_id       LA_T_9513704\n",
      "system_id                0\n",
      "label                    0\n",
      "Name: 10549, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_train.iloc[12754])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([10549], dtype='int64')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.loc[y_train.iloc[:,1]=='LA_T_9513704'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker_id         LA_0096\n",
       "file_id       LA_T_5159226\n",
       "system_id                5\n",
       "label                    1\n",
       "Name: 10792, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.iloc[10549,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "for s in range(0,128):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
