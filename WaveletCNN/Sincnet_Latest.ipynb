{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "J3R7P0a08iUH",
    "outputId": "e76cefff-ee7e-409b-fb13-7cc01f3857f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rohita/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQyX8ddJk32y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "import numpy as np\n",
    "# import librosa as lb\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import to_categorical,Sequence\n",
    "import pandas as pd\n",
    "import math\n",
    "import sincnet\n",
    "# from tensorflow import set_random_seed\n",
    "from keras import models, layers\n",
    "import numpy as np\n",
    "import sincnet\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import MaxPooling1D,MaxPooling2D, Conv1D, LeakyReLU, BatchNormalization, Dense, Flatten\n",
    "from keras.layers import InputLayer, Input\n",
    "from keras.models import Model\n",
    "# from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pywt\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "import tensorflow.contrib.slim as slim\n",
    "# import tfwavelets\n",
    "# sys.path.insert(1, '/content/drive/My Drive/SA/Code/spoof_detection_deep_features/WaveletCNN/cwt-tensorflow')\n",
    "# from cwt import cwtMortlet, cwtRicker,mortletWavelet, rickerWavelet\n",
    "# tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "# import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    Suppose `samples` is an array [[audio1,label1], [audio2,label2],...].\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    total_batches = int(data.shape[0])\n",
    "    for i in range(total_batches):\n",
    "        X_train,y_train = create_batches_rnd(data, labels, batch_size)\n",
    "        yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_val(data, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    Suppose `samples` is an array [[audio1,label1], [audio2,label2],...].\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    total_batches = int(data.shape[0])\n",
    "    for i in range(total_batches):\n",
    "        X_train,y_train = create_batches_rnd(data, labels, batch_size)\n",
    "        yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches_rnd(data,labels,batch_size):\n",
    "    wlen = 3200\n",
    "    fact_amp = 0.2\n",
    "    # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n",
    "    sig_batch=np.zeros([batch_size,wlen])\n",
    "#     wpt_batch = np.zeros([batch_size,wlen,1])\n",
    "    lab_batch=[]\n",
    "    signal_id_arr=np.random.randint(data.shape[0], size=batch_size)\n",
    "    rand_amp_arr = np.random.uniform(1.0-fact_amp,1+fact_amp,batch_size)\n",
    "    for i in range(batch_size): \n",
    "        # select a random sentence from the list \n",
    "        #[fs,signal]=scipy.io.wavfile.read(data_folder+wav_lst[snt_id_arr[i]])\n",
    "        #signal=signal.astype(float)/32768\n",
    "#         [signal, fs] = sf.read(data_folder+wav_lst[snt_id_arr[i]])\n",
    "        signal = data[signal_id_arr[i]]\n",
    "        # accesing to a random chunk\n",
    "        signal_len=signal.shape[0]\n",
    "        signal_beg=np.random.randint(signal_len-wlen-1) #randint(0, snt_len-2*wlen-1)\n",
    "        signal_end=signal_beg+wlen\n",
    "        sig_batch[i,:]=signal[signal_beg:signal_end]*rand_amp_arr[i]\n",
    "#         wpt = Wavelet_1d(signal[signal_beg:signal_end])\n",
    "#         wpt_batch[i,:] = wpt\n",
    "        y=labels[signal_id_arr[i]]\n",
    "#         yt = to_categorical(y, num_classes=out_dim)\n",
    "        lab_batch.append(y)\n",
    "    a, b = np.shape(sig_batch)\n",
    "    sig_batch = sig_batch.reshape((a, b, 1))\n",
    "    return sig_batch, np.array(lab_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_conv_block(X,in_channels,out_channels,stage,block,dilation=1):\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = BatchNormalization(name=bn_name_base+'a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv1D(in_channels, 3, padding='valid',use_bias = False, name= conv_name_base+'a')(X)\n",
    "    X = BatchNormalization(name=bn_name_base+'b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv1D(in_channels, 3, padding='valid',use_bias = False, name= conv_name_base+'b')(X)\n",
    "    print(X.shape)\n",
    "    paddings = tf.constant([[0, 0],   # the batch size dimension\n",
    "                          [2, 2],   # top and bottom of image\n",
    "                          [0, 0]])  # the channels dimension\n",
    "    X = Lambda(lambda x: tf.pad(x, paddings, mode='CONSTANT',\n",
    "                        constant_values=0.0))(X)\n",
    "    X = concatenate([X , X_shortcut])\n",
    "    X = BatchNormalization(name = bn_name_base+'c')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv1D(out_channels, 3, padding='valid',use_bias = False, dilation_rate = dilation, name = conv_name_base+'c')(X)\n",
    "\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 486, 128)\n",
      "(?, 478, 16)\n",
      "(?, 462, 8)\n",
      "(?, 430, 4)\n",
      "(?, 366, 2)\n"
     ]
    }
   ],
   "source": [
    "input_shape = None,3200,1\n",
    "    \n",
    "\n",
    "inputs = tf.placeholder(tf.float32, shape=input_shape, name= 'the_input')\n",
    "\n",
    "\n",
    "sinc = sincnet.SincConv1D(64, 251, 16000)(inputs)\n",
    "sinc_pool = MaxPooling1D(pool_size=3,name = 'sinc_pool')(sinc)\n",
    "sinc_norm = BatchNormalization(momentum=0.05, name = 'sinc_norm')(sinc_pool)\n",
    "sinc_layer_norm = sincnet.LayerNorm(name = 'sinc_layer_norm')(sinc_norm)\n",
    "sinc_relu = LeakyReLU(alpha=0.2, name = 'sinc_relu')(sinc_layer_norm)\n",
    "\n",
    "sinc_conv = Conv1D(64, 5, strides=2, padding='valid',kernel_initializer = keras.initializers.glorot_uniform(seed=0))(sinc_relu)\n",
    "# sinc_pool_1 = MaxPooling1D(pool_size=3,name = 'sinc_pool_1')(sinc_conv)\n",
    "sinc_norm_1 = BatchNormalization(momentum=0.05, name = 'sinc_norm_1')(sinc_conv)\n",
    "sinc_layer_norm_1 = sincnet.LayerNorm(name = 'sinc_layer_norm_1')(sinc_norm_1)\n",
    "sinc_relu_1 = LeakyReLU(alpha=0.2, name = 'sinc_relu_1')(sinc_layer_norm_1)\n",
    " \n",
    "#concate level one and level two decomposition\n",
    "# concate_level_2 = concatenate([relu_1_2,sinc_relu_1])\n",
    "# print(concate_level_2.shape)\n",
    "res_conv_1 = res_conv_block(sinc_relu_1, 128, 16, 1, 'a', 4)\n",
    "res_conv_2 = res_conv_block(res_conv_1, 16, 8, 2, 'a', 8)\n",
    "res_conv_3 = res_conv_block(res_conv_2, 8, 4, 3, 'a', 16)\n",
    "res_conv_4 = res_conv_block(res_conv_3, 4, 2, 4, 'a', 32)\n",
    "res_conv_5 = res_conv_block(res_conv_4, 2, 1, 5, 'a', 64)\n",
    "\n",
    "res_norm = BatchNormalization(name='res_norm')(res_conv_5)\n",
    "res_relu = Activation('relu')(res_norm)\n",
    "\n",
    "\n",
    "pool_5_1 = AveragePooling1D(pool_size=3, padding='same', name='avg_pool_5_1')(res_relu)\n",
    "flat_5_1 = Flatten(name='flat_5_1')(pool_5_1) \n",
    "\n",
    "fc_5 = Dense(2048, name='fc_5',kernel_initializer = keras.initializers.glorot_uniform(seed=0))(flat_5_1)\n",
    "norm_5 = BatchNormalization(name='norm_5')(fc_5)\n",
    "relu_5 = Activation('relu', name='relu_5')(norm_5)\n",
    "drop_5 = Dropout(0.5, name='drop_5')(relu_5)\n",
    "\n",
    "fc_6 = Dense(2048, name='fc_6',kernel_initializer = keras.initializers.glorot_uniform(seed=0))(drop_5)\n",
    "norm_6 = BatchNormalization(name='norm_6')(fc_6)\n",
    "relu_6 = Activation('relu', name='relu_6')(norm_6)\n",
    "drop_6 = Dropout(0.5, name='drop_6')(relu_6)\n",
    "\n",
    "output = Dense(2, activation=tf.nn.softmax)(drop_6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "sinc_conv1d_1/filt_b1:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_conv1d_1/filt_band:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_conv1d_1/Variable:0 (float32_ref 251) [251, bytes: 1004]\n",
      "sinc_conv1d_1/Variable_1:0 (float32_ref 125) [125, bytes: 500]\n",
      "sinc_conv1d_1/Variable_2:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_3:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_4:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_5:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_6:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_7:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_8:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_9:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_10:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_11:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_12:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_13:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_14:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_15:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_16:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_17:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_18:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_19:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_20:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_21:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_22:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_23:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_24:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_25:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_26:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_27:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_28:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_29:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_30:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_31:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_32:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_33:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_34:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_35:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_36:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_37:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_38:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_39:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_40:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_41:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_42:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_43:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_44:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_45:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_46:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_47:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_48:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_49:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_50:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_51:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_52:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_53:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_54:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_55:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_56:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_57:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_58:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_59:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_60:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_61:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_62:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_63:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_64:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_65:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_66:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_67:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_68:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_69:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_70:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_71:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_72:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_73:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_74:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_75:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_76:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_77:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_78:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_79:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_80:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_81:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_82:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_83:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_84:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_85:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_86:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_87:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_88:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_89:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_90:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_91:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_92:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_93:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_94:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_95:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_96:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_97:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_98:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_99:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_100:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_101:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_102:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_103:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_104:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_105:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_106:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_107:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_108:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_109:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_110:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_111:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_112:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_113:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_114:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_115:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_116:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_117:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_118:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_119:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_120:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_121:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_122:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_123:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_124:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_125:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_126:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_127:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_128:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_129:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_130:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_131:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_132:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_133:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_134:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_135:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_136:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_137:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_138:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_139:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_140:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_141:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_142:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_143:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_144:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_145:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_146:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_147:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_148:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_149:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_150:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_151:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_152:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_153:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_154:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_155:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_156:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_157:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_158:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_159:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_160:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_161:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_162:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_163:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_164:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_165:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_166:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_167:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_168:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_169:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_170:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_171:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_172:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_173:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_174:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_175:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_176:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_177:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_178:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_179:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_180:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_181:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_182:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_183:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_184:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_185:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_186:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_187:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_188:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_189:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_190:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_191:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_192:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_193:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_194:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_195:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_196:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_197:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_198:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_199:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_200:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_201:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_202:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_203:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_204:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_205:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_206:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_207:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_208:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_209:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_210:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_211:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_212:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_213:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_214:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_215:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_216:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_217:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_218:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_219:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_220:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_221:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_222:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_223:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_224:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_225:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_226:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_227:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_228:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_229:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_230:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_231:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_232:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_233:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_234:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_235:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_236:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_237:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_238:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_239:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_240:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_241:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_242:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_243:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_244:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_245:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_246:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_247:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_248:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_249:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_250:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_251:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_252:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_253:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_254:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_255:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_256:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_257:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_norm/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm/moving_mean:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm/moving_variance:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_layer_norm/sinc_layer_norm_scale:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_layer_norm/sinc_layer_norm_bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "conv1d_1/kernel:0 (float32_ref 5x64x64) [20480, bytes: 81920]\n",
      "conv1d_1/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm_1/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm_1/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm_1/moving_mean:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm_1/moving_variance:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_layer_norm_1/sinc_layer_norm_1_scale:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_layer_norm_1/sinc_layer_norm_1_bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "bn1a_brancha/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "bn1a_brancha/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "bn1a_brancha/moving_mean:0 (float32_ref 64) [64, bytes: 256]\n",
      "bn1a_brancha/moving_variance:0 (float32_ref 64) [64, bytes: 256]\n",
      "res1a_brancha/kernel:0 (float32_ref 3x64x128) [24576, bytes: 98304]\n",
      "bn1a_branchb/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "bn1a_branchb/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "bn1a_branchb/moving_mean:0 (float32_ref 128) [128, bytes: 512]\n",
      "bn1a_branchb/moving_variance:0 (float32_ref 128) [128, bytes: 512]\n",
      "res1a_branchb/kernel:0 (float32_ref 3x128x128) [49152, bytes: 196608]\n",
      "bn1a_branchc/gamma:0 (float32_ref 192) [192, bytes: 768]\n",
      "bn1a_branchc/beta:0 (float32_ref 192) [192, bytes: 768]\n",
      "bn1a_branchc/moving_mean:0 (float32_ref 192) [192, bytes: 768]\n",
      "bn1a_branchc/moving_variance:0 (float32_ref 192) [192, bytes: 768]\n",
      "res1a_branchc/kernel:0 (float32_ref 3x192x16) [9216, bytes: 36864]\n",
      "bn2a_brancha/gamma:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_brancha/beta:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_brancha/moving_mean:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_brancha/moving_variance:0 (float32_ref 16) [16, bytes: 64]\n",
      "res2a_brancha/kernel:0 (float32_ref 3x16x16) [768, bytes: 3072]\n",
      "bn2a_branchb/gamma:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_branchb/beta:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_branchb/moving_mean:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_branchb/moving_variance:0 (float32_ref 16) [16, bytes: 64]\n",
      "res2a_branchb/kernel:0 (float32_ref 3x16x16) [768, bytes: 3072]\n",
      "bn2a_branchc/gamma:0 (float32_ref 32) [32, bytes: 128]\n",
      "bn2a_branchc/beta:0 (float32_ref 32) [32, bytes: 128]\n",
      "bn2a_branchc/moving_mean:0 (float32_ref 32) [32, bytes: 128]\n",
      "bn2a_branchc/moving_variance:0 (float32_ref 32) [32, bytes: 128]\n",
      "res2a_branchc/kernel:0 (float32_ref 3x32x8) [768, bytes: 3072]\n",
      "bn3a_brancha/gamma:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_brancha/beta:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_brancha/moving_mean:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_brancha/moving_variance:0 (float32_ref 8) [8, bytes: 32]\n",
      "res3a_brancha/kernel:0 (float32_ref 3x8x8) [192, bytes: 768]\n",
      "bn3a_branchb/gamma:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_branchb/beta:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_branchb/moving_mean:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_branchb/moving_variance:0 (float32_ref 8) [8, bytes: 32]\n",
      "res3a_branchb/kernel:0 (float32_ref 3x8x8) [192, bytes: 768]\n",
      "bn3a_branchc/gamma:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn3a_branchc/beta:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn3a_branchc/moving_mean:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn3a_branchc/moving_variance:0 (float32_ref 16) [16, bytes: 64]\n",
      "res3a_branchc/kernel:0 (float32_ref 3x16x4) [192, bytes: 768]\n",
      "bn4a_brancha/gamma:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_brancha/beta:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_brancha/moving_mean:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_brancha/moving_variance:0 (float32_ref 4) [4, bytes: 16]\n",
      "res4a_brancha/kernel:0 (float32_ref 3x4x4) [48, bytes: 192]\n",
      "bn4a_branchb/gamma:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_branchb/beta:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_branchb/moving_mean:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_branchb/moving_variance:0 (float32_ref 4) [4, bytes: 16]\n",
      "res4a_branchb/kernel:0 (float32_ref 3x4x4) [48, bytes: 192]\n",
      "bn4a_branchc/gamma:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn4a_branchc/beta:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn4a_branchc/moving_mean:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn4a_branchc/moving_variance:0 (float32_ref 8) [8, bytes: 32]\n",
      "res4a_branchc/kernel:0 (float32_ref 3x8x2) [48, bytes: 192]\n",
      "bn5a_brancha/gamma:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_brancha/beta:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_brancha/moving_mean:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_brancha/moving_variance:0 (float32_ref 2) [2, bytes: 8]\n",
      "res5a_brancha/kernel:0 (float32_ref 3x2x2) [12, bytes: 48]\n",
      "bn5a_branchb/gamma:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_branchb/beta:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_branchb/moving_mean:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_branchb/moving_variance:0 (float32_ref 2) [2, bytes: 8]\n",
      "res5a_branchb/kernel:0 (float32_ref 3x2x2) [12, bytes: 48]\n",
      "bn5a_branchc/gamma:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn5a_branchc/beta:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn5a_branchc/moving_mean:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn5a_branchc/moving_variance:0 (float32_ref 4) [4, bytes: 16]\n",
      "res5a_branchc/kernel:0 (float32_ref 3x4x1) [12, bytes: 48]\n",
      "res_norm/gamma:0 (float32_ref 1) [1, bytes: 4]\n",
      "res_norm/beta:0 (float32_ref 1) [1, bytes: 4]\n",
      "res_norm/moving_mean:0 (float32_ref 1) [1, bytes: 4]\n",
      "res_norm/moving_variance:0 (float32_ref 1) [1, bytes: 4]\n",
      "fc_5/kernel:0 (float32_ref 81x2048) [165888, bytes: 663552]\n",
      "fc_5/bias:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_5/gamma:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_5/beta:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_5/moving_mean:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_5/moving_variance:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "fc_6/kernel:0 (float32_ref 2048x2048) [4194304, bytes: 16777216]\n",
      "fc_6/bias:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_6/gamma:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_6/beta:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_6/moving_mean:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_6/moving_variance:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "dense_1/kernel:0 (float32_ref 2048x2) [4096, bytes: 16384]\n",
      "dense_1/bias:0 (float32_ref 2) [2, bytes: 8]\n",
      "Total size of variables: 4494866\n",
      "Total bytes of variables: 17979464\n"
     ]
    }
   ],
   "source": [
    "def model_summary():\n",
    "    model_vars = tf.trainable_variables()\n",
    "    slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n",
    "\n",
    "model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMVZpBEd9EO5"
   },
   "outputs": [],
   "source": [
    "labels = tf.placeholder(tf.float32, shape=(None,2))\n",
    "\n",
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    acc= tf.reduce_mean(accuracy(labels, output))\n",
    "\n",
    "from keras.objectives import categorical_crossentropy\n",
    "with tf.name_scope('Loss'):\n",
    "    loss = tf.reduce_mean(categorical_crossentropy(labels, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train.npy\")\n",
    "# y_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train_labels.npy\")\n",
    "# y_train=list(y_train)\n",
    "\n",
    "# y_train1 = list()\n",
    "# for i in y_train:\n",
    "#     if i == b'bonafide':\n",
    "#         y_train1.append(1)\n",
    "#     else:\n",
    "#         y_train1.append(0)\n",
    "# y_train = to_categorical(y_train1)\n",
    "# # X_dev_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_train.npy\")\n",
    "# # X_dev_val = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_val.npy\")\n",
    "# # y_dev_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_train_labels.npy\")\n",
    "# # y_dev_val = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_val_labels.npy\")\n",
    "# # dev_wpt_levels_data_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_wpt_levels_data_train.npy\")\n",
    "# # dev_wpt_levels_data_val = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_wpt_levels_data_val.npy\")\n",
    "# # wpt_levels_data_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train_wpt_levels_data_train.npy\")\n",
    "# X_val = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_val.npy\")\n",
    "y_val = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_train_labels.npy\")\n",
    "# y_val=list(y_val)\n",
    "\n",
    "# y_val1 = list()\n",
    "# for i in y_val:\n",
    "#     if i == b'bonafide':\n",
    "#         y_val1.append(1)\n",
    "#     else:\n",
    "#         y_val1.append(0)\n",
    "\n",
    "# y_val = to_categorical(y_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = X_train.sum(axis=1)\n",
    "X_train = X_train / row_sums[:, np.newaxis]\n",
    "row_sums = X_val.sum(axis=1)\n",
    "X_val = X_val / row_sums[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0HzJnZ4e_PJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0step: 0Training loss:  0.6931472   Training accuracy   0.4765625\n",
      "Epoch: 0step: 1Training loss:  0.69314724   Training accuracy   0.5\n",
      "Epoch: 0step: 2Training loss:  0.69314605   Training accuracy   0.5390625\n",
      "Epoch: 0step: 3Training loss:  0.693145   Training accuracy   0.5390625\n",
      "Epoch: 0step: 4Training loss:  0.6931455   Training accuracy   0.5234375\n",
      "Epoch: 0step: 5Training loss:  0.6931431   Training accuracy   0.5390625\n",
      "Epoch: 0step: 6Training loss:  0.69313884   Training accuracy   0.5546875\n",
      "Epoch: 0step: 7Training loss:  0.69314307   Training accuracy   0.5234375\n",
      "Epoch: 0step: 8Training loss:  0.69313467   Training accuracy   0.5546875\n",
      "Epoch: 0step: 9Training loss:  0.69314116   Training accuracy   0.5234375\n",
      "Epoch: 0step: 10Training loss:  0.6931169   Training accuracy   0.5859375\n",
      "Epoch: 0step: 11Training loss:  0.6931652   Training accuracy   0.4296875\n",
      "Epoch: 0step: 12Training loss:  0.6931569   Training accuracy   0.4453125\n",
      "Epoch: 0step: 13Training loss:  0.69315124   Training accuracy   0.46875\n",
      "Epoch: 0step: 14Training loss:  0.6931416   Training accuracy   0.53125\n",
      "Epoch: 0step: 15Training loss:  0.6931421   Training accuracy   0.5234375\n",
      "Epoch: 0step: 16Training loss:  0.69315404   Training accuracy   0.4296875\n",
      "Epoch: 0step: 17Training loss:  0.69314796   Training accuracy   0.453125\n",
      "Epoch: 0step: 18Training loss:  0.693147   Training accuracy   0.515625\n",
      "Epoch: 0step: 19Training loss:  0.6931393   Training accuracy   0.5703125\n",
      "Epoch: 0step: 20Training loss:  0.69314355   Training accuracy   0.5234375\n",
      "Epoch: 0step: 21Training loss:  0.6931499   Training accuracy   0.4453125\n",
      "Epoch: 0step: 22Training loss:  0.6931449   Training accuracy   0.5234375\n",
      "Epoch: 0step: 23Training loss:  0.69312   Training accuracy   0.59375\n",
      "Epoch: 0step: 24Training loss:  0.6931448   Training accuracy   0.5078125\n",
      "Epoch: 0step: 25Training loss:  0.693128   Training accuracy   0.546875\n",
      "Epoch: 0step: 26Training loss:  0.69313633   Training accuracy   0.5234375\n",
      "Epoch: 0step: 27Training loss:  0.6931472   Training accuracy   0.5\n",
      "val loss:  0.6931616   val accuracy   0.46875\n",
      "val loss:  0.69313276   val accuracy   0.53125\n",
      "val loss:  0.69313633   val accuracy   0.5234375\n",
      "val loss:  0.69315803   val accuracy   0.4765625\n",
      "val loss:  0.69313633   val accuracy   0.5234375\n",
      "val loss:  0.69314355   val accuracy   0.5078125\n",
      "val loss:  0.6931436   val accuracy   0.5078125\n",
      "val loss:  0.6931436   val accuracy   0.5078125\n",
      "val loss:  0.69313633   val accuracy   0.5234375\n",
      "val loss:  0.6931038   val accuracy   0.59375\n",
      "val loss:  0.6931508   val accuracy   0.4921875\n",
      "val loss:  0.69313276   val accuracy   0.53125\n",
      "Epoch: 1step: 0Training loss:  0.69311994   Training accuracy   0.546875\n",
      "Epoch: 1step: 1Training loss:  0.6931556   Training accuracy   0.484375\n",
      "Epoch: 1step: 2Training loss:  0.6931157   Training accuracy   0.546875\n",
      "Epoch: 1step: 3Training loss:  0.6931232   Training accuracy   0.53125\n",
      "Epoch: 1step: 4Training loss:  0.69317204   Training accuracy   0.4609375\n",
      "Epoch: 1step: 5Training loss:  0.69315207   Training accuracy   0.4921875\n",
      "Epoch: 1step: 6Training loss:  0.69314724   Training accuracy   0.5\n",
      "Epoch: 1step: 7Training loss:  0.6931176   Training accuracy   0.5390625\n",
      "Epoch: 1step: 8Training loss:  0.693158   Training accuracy   0.484375\n",
      "Epoch: 1step: 9Training loss:  0.693161   Training accuracy   0.4765625\n",
      "Epoch: 1step: 10Training loss:  0.69313085   Training accuracy   0.5234375\n",
      "Epoch: 1step: 11Training loss:  0.6931642   Training accuracy   0.46875\n",
      "Epoch: 1step: 12Training loss:  0.69314724   Training accuracy   0.5\n",
      "Epoch: 1step: 13Training loss:  0.6931473   Training accuracy   0.5\n",
      "Epoch: 1step: 14Training loss:  0.6931472   Training accuracy   0.5\n",
      "Epoch: 1step: 15Training loss:  0.6931521   Training accuracy   0.4140625\n",
      "Epoch: 1step: 16Training loss:  0.69314486   Training accuracy   0.515625\n",
      "Epoch: 1step: 17Training loss:  0.6931366   Training accuracy   0.53125\n",
      "Epoch: 1step: 18Training loss:  0.69313574   Training accuracy   0.5234375\n",
      "Epoch: 1step: 19Training loss:  0.693132   Training accuracy   0.5234375\n",
      "Epoch: 1step: 20Training loss:  0.69314724   Training accuracy   0.5\n",
      "Epoch: 1step: 21Training loss:  0.69313526   Training accuracy   0.515625\n",
      "Epoch: 1step: 22Training loss:  0.69316554   Training accuracy   0.453125\n",
      "Epoch: 1step: 23Training loss:  0.69312996   Training accuracy   0.6015625\n",
      "Epoch: 1step: 24Training loss:  0.69313467   Training accuracy   0.5390625\n",
      "Epoch: 1step: 25Training loss:  0.6931472   Training accuracy   0.5\n",
      "Epoch: 1step: 26Training loss:  0.693141   Training accuracy   0.515625\n",
      "Epoch: 1step: 27Training loss:  0.69315517   Training accuracy   0.4609375\n",
      "val loss:  0.6931488   val accuracy   0.4921875\n",
      "val loss:  0.69313276   val accuracy   0.5703125\n",
      "val loss:  0.6931536   val accuracy   0.46875\n",
      "val loss:  0.6931376   val accuracy   0.546875\n",
      "val loss:  0.6931472   val accuracy   0.5\n",
      "val loss:  0.6931504   val accuracy   0.484375\n",
      "val loss:  0.6931408   val accuracy   0.53125\n",
      "val loss:  0.69315684   val accuracy   0.453125\n",
      "val loss:  0.69314396   val accuracy   0.515625\n",
      "val loss:  0.69316   val accuracy   0.4375\n",
      "val loss:  0.6931472   val accuracy   0.5\n",
      "val loss:  0.693136   val accuracy   0.5546875\n",
      "Epoch: 2step: 0Training loss:  0.6931436   Training accuracy   0.5625\n",
      "Epoch: 2step: 1Training loss:  0.69313526   Training accuracy   0.546875\n",
      "Epoch: 2step: 2Training loss:  0.6931355   Training accuracy   0.53125\n",
      "Epoch: 2step: 3Training loss:  0.69315493   Training accuracy   0.46875\n",
      "Epoch: 2step: 4Training loss:  0.6931472   Training accuracy   0.5\n",
      "Epoch: 2step: 5Training loss:  0.6931212   Training accuracy   0.5546875\n",
      "Epoch: 2step: 6Training loss:  0.6931535   Training accuracy   0.484375\n",
      "Epoch: 2step: 7Training loss:  0.6931555   Training accuracy   0.4375\n",
      "Epoch: 2step: 8Training loss:  0.6931422   Training accuracy   0.5546875\n",
      "Epoch: 2step: 9Training loss:  0.69313765   Training accuracy   0.5390625\n",
      "Epoch: 2step: 10Training loss:  0.6931394   Training accuracy   0.59375\n",
      "Epoch: 2step: 11Training loss:  0.6931449   Training accuracy   0.5390625\n",
      "Epoch: 2step: 12Training loss:  0.6931438   Training accuracy   0.5234375\n",
      "Epoch: 2step: 13Training loss:  0.69313204   Training accuracy   0.546875\n",
      "Epoch: 2step: 14Training loss:  0.69315374   Training accuracy   0.4609375\n",
      "Epoch: 2step: 15Training loss:  0.6931344   Training accuracy   0.5390625\n",
      "Epoch: 2step: 16Training loss:  0.69314945   Training accuracy   0.4921875\n",
      "Epoch: 2step: 17Training loss:  0.6931242   Training accuracy   0.546875\n",
      "Epoch: 2step: 18Training loss:  0.69310784   Training accuracy   0.5546875\n",
      "Epoch: 2step: 19Training loss:  0.6931126   Training accuracy   0.5390625\n",
      "Epoch: 2step: 20Training loss:  0.693154   Training accuracy   0.4921875\n",
      "Epoch: 2step: 21Training loss:  0.6930975   Training accuracy   0.546875\n",
      "Epoch: 2step: 22Training loss:  0.6930126   Training accuracy   0.59375\n",
      "Epoch: 2step: 23Training loss:  0.69317865   Training accuracy   0.4765625\n",
      "Epoch: 2step: 24Training loss:  0.69316715   Training accuracy   0.484375\n",
      "Epoch: 2step: 25Training loss:  0.6931744   Training accuracy   0.4765625\n",
      "Epoch: 2step: 26Training loss:  0.6931068   Training accuracy   0.53125\n",
      "Epoch: 2step: 27Training loss:  0.69312584   Training accuracy   0.515625\n",
      "val loss:  0.69323367   val accuracy   0.4375\n",
      "val loss:  0.6932013   val accuracy   0.4609375\n",
      "val loss:  0.69309354   val accuracy   0.5390625\n",
      "val loss:  0.6932121   val accuracy   0.453125\n",
      "val loss:  0.6930828   val accuracy   0.546875\n",
      "val loss:  0.6932229   val accuracy   0.4453125\n",
      "val loss:  0.6931259   val accuracy   0.515625\n",
      "val loss:  0.69308275   val accuracy   0.546875\n",
      "val loss:  0.6931797   val accuracy   0.4765625\n",
      "val loss:  0.69305044   val accuracy   0.5703125\n",
      "val loss:  0.6932228   val accuracy   0.4453125\n",
      "val loss:  0.6931797   val accuracy   0.4765625\n",
      "Epoch: 3step: 0Training loss:  0.6931124   Training accuracy   0.5234375\n",
      "Epoch: 3step: 1Training loss:  0.6931355   Training accuracy   0.5078125\n",
      "Epoch: 3step: 2Training loss:  0.6930294   Training accuracy   0.5625\n",
      "Epoch: 3step: 3Training loss:  0.69281   Training accuracy   0.6171875\n",
      "Epoch: 3step: 4Training loss:  0.6930388   Training accuracy   0.53125\n",
      "Epoch: 3step: 5Training loss:  0.6932515   Training accuracy   0.4609375\n",
      "Epoch: 3step: 6Training loss:  0.6932311   Training accuracy   0.4609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3step: 7Training loss:  0.69317746   Training accuracy   0.484375\n",
      "Epoch: 3step: 8Training loss:  0.69322646   Training accuracy   0.4296875\n",
      "Epoch: 3step: 9Training loss:  0.693184   Training accuracy   0.4296875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b3b381b1507c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summary_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtrain_summary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_batch_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rohit/spoof/work3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.name_scope('RMSProp'):\n",
    "    # Gradient Descent\n",
    "    optimizer = tf.train.RMSPropOptimizer(0.0001)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "    # Op to calculate every variable gradient\n",
    "\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", acc)\n",
    "# Create summaries to visualize weights\n",
    "# for var in tf.trainable_variables():\n",
    "#     tf.summary.histogram(var.name, var)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "# Initialize all variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 128\n",
    "logs_path = '/home/rohita/rohit/spoof/npy_data_asvspoof/Sincnet'\n",
    "\n",
    "# Run training loop\n",
    "with sess.as_default():\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    train_summary_writer = tf.summary.FileWriter(logs_path+'/Train_correct',\n",
    "                                            graph=tf.get_default_graph())\n",
    "    val_summary_writer = tf.summary.FileWriter(logs_path+'/Val_correct')\n",
    "    gen = generator(X_train, y_train, batch_size)\n",
    "    gen_val = generator_val(X_val, y_val, batch_size)\n",
    "    total_batch_train = int(X_train.shape[0]/batch_size)\n",
    "    total_batch_val = int(X_val.shape[0]/batch_size)\n",
    "    for epoch in range(100):\n",
    "        for i in range(total_batch_train):\n",
    "            X_batch, y_batch = next(gen)\n",
    "            feed_dict = {inputs: X_batch, labels: y_batch, tf.keras.backend.learning_phase(): 1}\n",
    "            sess.run(train_step,feed_dict)\n",
    "            loss_train, acc_train, summary = (sess.run([loss, acc, merged_summary_op],feed_dict))\n",
    "            train_summary_writer.add_summary(summary, epoch * total_batch_train + i)\n",
    "            print(\"Epoch: \"+str(epoch)+\"step: \"+str(i)+\"Training loss: \",loss_train,\" \",\"Training accuracy\",\" \",acc_train)\n",
    "        \n",
    "#             loss_val,acc_val = (sess.run([loss,acc_value],feed_dict={inputs: X_batch, labels: y_batch, tf.keras.backend.learning_phase(): 0}))\n",
    "#             print(\"Epoch: \"+str(i)+\"step: \"+str(step)+\"loss: \",loss_val,\" \",\"accuracy\",\" \",acc_val)\n",
    "            \n",
    "                    \n",
    "        for i in range(total_batch_val):\n",
    "            X_batch, y_batch = next(gen_val)\n",
    "            loss_val, acc_val, summary = (sess.run([loss, acc, merged_summary_op],feed_dict={inputs: X_batch, labels: y_batch, tf.keras.backend.learning_phase(): 0}))\n",
    "            val_summary_writer.add_summary(summary, epoch * total_batch_val + i)\n",
    "            print(\"val loss: \",loss_val,\" \",\"val accuracy\",\" \",acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WaveletCNN_Latest_ASVspoof2015.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
