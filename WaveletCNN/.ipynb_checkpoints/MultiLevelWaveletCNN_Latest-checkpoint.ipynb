{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "VnEyfmhu8mN6",
    "outputId": "50232f8b-d446-4e4b-cabe-fff7d1b32ca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RnfSUDv183Cz",
    "outputId": "7fd3e060-112c-45d3-d65f-583f89e41dcf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/SA/Code/spoof_detection_deep_features/WaveletCNN\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/SA/Code/spoof_detection_deep_features/WaveletCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run code from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Collecting keras==2.0.8\n",
      "  Using cached Keras-2.0.8-py2.py3-none-any.whl (276 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from keras==2.0.8) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python2.7/dist-packages (from keras==2.0.8) (1.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from keras==2.0.8) (3.12)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python2.7/dist-packages (from keras==2.0.8) (1.15.1)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.2.4\n",
      "    Uninstalling Keras-2.2.4:\n",
      "      Successfully uninstalled Keras-2.2.4\n",
      "Successfully installed keras-2.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "J3R7P0a08iUH",
    "outputId": "e76cefff-ee7e-409b-fb13-7cc01f3857f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQyX8ddJk32y"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (nodes.py, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/rohita/rohit/spoof/work/local/lib/python2.7/site-packages/tfwavelets/nodes.py\"\u001b[0;36m, line \u001b[0;32m49\u001b[0m\n\u001b[0;31m    tl = tl_node @ tf.transpose(tl_slice, perm=[2, 1, 0])\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "import math\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.layers import MaxPooling1D,MaxPooling2D,AveragePooling1D, Conv1D, LeakyReLU, BatchNormalization, Dense, Flatten, concatenate, Activation\n",
    "from tensorflow.python.keras.layers import InputLayer, Input, Layer, Lambda, Dropout\n",
    "from tensorflow.python.keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tfwavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p85kAJ4i9B8a"
   },
   "outputs": [],
   "source": [
    "img = tf.placeholder(tf.float32, shape=(None, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08soF5zXGSGy"
   },
   "outputs": [],
   "source": [
    "# def framing_windowing(signal):\n",
    "#   pre_emphasis = 0.97\n",
    "#   frame_size = 256\n",
    "#   frame_stride = 128\n",
    "#   nfilt = 20\n",
    "#   NFFT = 511\n",
    "#   emphasized_signal = tf.concat([tf.reshape(signal[:,0],[tf.shape(signal)[0],1]),(signal[:,1:] - pre_emphasis * signal[:,:-1])],axis =1)\n",
    "#   print(emphasized_signal.shape)\n",
    "#   frame_length, frame_step = frame_size, frame_stride  # Convert from seconds to samples\n",
    "#   signal_frames=tf.signal.frame(emphasized_signal,frame_length, frame_step)\n",
    "#   signal_frames *=tf.signal.hamming_window(frame_length)\n",
    "#   print(signal_frames.shape)\n",
    "#   return signal_frames\n",
    "def framing_windowing(signal):\n",
    "    pre_emphasis = 0.97\n",
    "    frame_size = 3200\n",
    "    frame_stride = 160\n",
    "    nfilt = 20\n",
    "    emphasized_signal = np.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "    frame_length, frame_step = frame_size, frame_stride  # Convert from seconds to samples\n",
    "    signal_length = len(emphasized_signal)\n",
    "    frame_length = int(round(frame_length))\n",
    "    frame_step = int(round(frame_step))\n",
    "    num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
    "#     print(num_frames)\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = np.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = np.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "    frames *= np.hamming(frame_length)\n",
    "    # print(frames.shape)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwHzqvPGu3bi"
   },
   "outputs": [],
   "source": [
    "# def tkeo_new(a):\n",
    "\n",
    "#     \"\"\"\n",
    "#     Calculates the TKEO of a given recording by using 2 samples.\n",
    "#     See Li et al., 2007\n",
    "#     Arguments:\n",
    "#     a \t\t\t--- 1D numpy array.\n",
    "#     Returns:\n",
    "#     1D numpy array containing the tkeo per sample\n",
    "#     \"\"\"\n",
    "#     # Create two temporary arrays of equal length, shifted 1 sample to the right\n",
    "#     # and left and squared:\n",
    "#     i = a[:,:,1:-1]*a[:,:,1:-1]\n",
    "#     j = a[:,:,2:]*a[:,:,:-2]\n",
    "#     # Calculate the difference between the two temporary arrays:\n",
    "#     aTkeo = i-j\n",
    "#     return aTkeo\n",
    "def tkeo(a):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the TKEO of a given recording by using 2 samples.\n",
    "    See Li et al., 2007\n",
    "    Arguments:\n",
    "    a \t\t\t--- 1D numpy array.\n",
    "    Returns:\n",
    "    1D numpy array containing the tkeo per sample\n",
    "    \"\"\"\n",
    "    # Create two temporary arrays of equal length, shifted 1 sample to the right\n",
    "    # and left and squared:\n",
    "    i = a[1:-1]*a[1:-1]\n",
    "    j = a[2:]*a[:-2]\n",
    "    # Calculate the difference between the two temporary arrays:\n",
    "    aTkeo = i-j\n",
    "    return aTkeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    Suppose `samples` is an array [[audio1,label1], [audio2,label2],...].\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        X_train,y_train = create_batches_rnd(data, labels, batch_size)\n",
    "        yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_val(data, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    Suppose `samples` is an array [[audio1,label1], [audio2,label2],...].\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        X_train,y_train = create_batches_rnd(data, labels, batch_size)\n",
    "        yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_part1(data, labels,batch_size):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    Suppose `samples` is an array [[audio1,label1], [audio2,label2],...].\n",
    "    \"\"\"\n",
    "    x_samples = []\n",
    "    y_samples = []\n",
    "    for count,i in enumerate(data):\n",
    "        x_samples = framing_windowing(i)\n",
    "        num_samples = len(x_samples)\n",
    "        y_samples = [labels[count]]*num_samples\n",
    "#         print(\"yo\")\n",
    " \n",
    "      # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size <= num_samples]\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "        # Get the samples you'll use in this batch\n",
    "            batch_samples = x_samples[offset:offset+batch_size]\n",
    "\n",
    "        # Initialise X_train and y_train arrays for this batch\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            wpt = []\n",
    "        # For each example\n",
    "            for count,x_sample in enumerate(batch_samples):\n",
    "            # audio (X) and label (y)\n",
    "                audio =  x_sample\n",
    "#             print(level1.shape)\n",
    "                label = y_samples[count]\n",
    "            \n",
    "            # Add example to arrays\n",
    "                X_train.append(audio)\n",
    "                y_train.append(label)\n",
    "                wpt.append(Wavelet_1d(audio))\n",
    "\n",
    "\n",
    "        # Make sure they're numpy arrays (as opposed to lists)\n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train)\n",
    "#             print(y_train)\n",
    "#             y_train = to_categorical(y_train)\n",
    "            wpt = np.array(wpt)\n",
    "#             print(y_train.shape)\n",
    "        # The generator-y part: yield the next training batch            \n",
    "            yield X_train,wpt, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches_rnd(data,labels,batch_size):\n",
    "    wlen = 3200\n",
    "    fact_amp = 0.2\n",
    "    # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n",
    "    sig_batch=np.zeros([batch_size,wlen])\n",
    "    wpt_batch = np.zeros([batch_size,wlen,1])\n",
    "    lab_batch=[]\n",
    "    signal_id_arr=np.random.randint(data.shape[0], size=batch_size)\n",
    "    rand_amp_arr = np.random.uniform(1.0-fact_amp,1+fact_amp,batch_size)\n",
    "    for i in range(batch_size): \n",
    "        # select a random sentence from the list \n",
    "        #[fs,signal]=scipy.io.wavfile.read(data_folder+wav_lst[snt_id_arr[i]])\n",
    "        #signal=signal.astype(float)/32768\n",
    "#         [signal, fs] = sf.read(data_folder+wav_lst[snt_id_arr[i]])\n",
    "        signal = data[signal_id_arr[i]]\n",
    "        # accesing to a random chunk\n",
    "        signal_len=signal.shape[0]\n",
    "        signal_beg=np.random.randint(signal_len-wlen-1) #randint(0, snt_len-2*wlen-1)\n",
    "        signal_end=signal_beg+wlen\n",
    "        sig_batch[i,:]=signal[signal_beg:signal_end]*rand_amp_arr[i]\n",
    "        wpt = Wavelet_1d(signal[signal_beg:signal_end])\n",
    "        wpt_batch[i,:] = wpt\n",
    "        y=labels[signal_id_arr[i]]\n",
    "#         yt = to_categorical(y, num_classes=out_dim)\n",
    "        lab_batch.append(y)\n",
    "    a, b = np.shape(sig_batch)\n",
    "    sig_batch = sig_batch.reshape((a, b, 1))\n",
    "    return sig_batch, wpt_batch, np.array(lab_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches_rnd(data,labels,batch_size):\n",
    "    wlen = 3200\n",
    "    fact_amp = 0.2\n",
    "    # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n",
    "    sig_batch=np.zeros([batch_size,wlen])\n",
    "#     wpt_batch = np.zeros([batch_size,wlen,1])\n",
    "    lab_batch=[]\n",
    "    signal_id_arr=np.random.randint(data.shape[0], size=batch_size)\n",
    "    rand_amp_arr = np.random.uniform(1.0-fact_amp,1+fact_amp,batch_size)\n",
    "    for i in range(batch_size): \n",
    "        # select a random sentence from the list \n",
    "        #[fs,signal]=scipy.io.wavfile.read(data_folder+wav_lst[snt_id_arr[i]])\n",
    "        #signal=signal.astype(float)/32768\n",
    "#         [signal, fs] = sf.read(data_folder+wav_lst[snt_id_arr[i]])\n",
    "        signal = data[signal_id_arr[i]]\n",
    "        # accesing to a random chunk\n",
    "        signal_len=signal.shape[0]\n",
    "        signal_beg=np.random.randint(signal_len-wlen-1) #randint(0, snt_len-2*wlen-1)\n",
    "        signal_end=signal_beg+wlen\n",
    "        sig_batch[i,:]=signal[signal_beg:signal_end]*rand_amp_arr[i]\n",
    "#         wpt = Wavelet_1d(signal[signal_beg:signal_end])\n",
    "#         wpt_batch[i,:] = wpt\n",
    "        y=labels[signal_id_arr[i]]\n",
    "#         yt = to_categorical(y, num_classes=out_dim)\n",
    "        lab_batch.append(y)\n",
    "    a, b = np.shape(sig_batch)\n",
    "    sig_batch = sig_batch.reshape((a, b, 1))\n",
    "    return sig_batch, np.array(lab_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_val(x_samples, y_samples, batch_size):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    Suppose `samples` is an array [[audio1,label1], [audio2,label2],...].\n",
    "    \"\"\"\n",
    "    \n",
    "    num_samples = len(x_samples)\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        \n",
    "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size <= num_samples]\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            # Get the samples you'll use in this batch\n",
    "            batch_samples = x_samples[offset:offset+batch_size]\n",
    "\n",
    "            # Initialise X_train and y_train arrays for this batch\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            wpt = []\n",
    "            # For each example\n",
    "            for count,x_sample in enumerate(batch_samples):\n",
    "                # audio (X) and label (y)\n",
    "                audio =  x_sample\n",
    "#                 print(level1.shape)\n",
    "                label = y_samples[count]\n",
    "                \n",
    "                # Add example to arrays\n",
    "                X_train.append(audio)\n",
    "                y_train.append(label)\n",
    "                wpt.append(Wavelet_1d(audio))\n",
    "\n",
    "\n",
    "            # Make sure they're numpy arrays (as opposed to lists)\n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train)\n",
    "            y_train = to_categorical(y_train)\n",
    "            wpt = np.array(wpt)\n",
    "#             print(\"hello\")\n",
    "            # The generator-y part: yield the next training batch            \n",
    "            yield X_train, wpt, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_val_part1(data, labels):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    Suppose `samples` is an array [[audio1,label1], [audio2,label2],...].\n",
    "    \"\"\"\n",
    "    x_samples = []\n",
    "    y_samples = []\n",
    "    for count,i in enumerate(data):\n",
    "        x_samples = framing_windowing(i)\n",
    "        num_samples = len(x_samples)\n",
    "        y_samples = [labels[count]]*num_samples\n",
    "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size <= num_samples]\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            # Get the samples you'll use in this batch\n",
    "            batch_samples = x_samples[offset:offset+batch_size]\n",
    "\n",
    "            # Initialise X_train and y_train arrays for this batch\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            wpt = []\n",
    "            # For each example\n",
    "            for count,x_sample in enumerate(batch_samples):\n",
    "                # audio (X) and label (y)\n",
    "                audio =  x_sample\n",
    "#                 print(level1.shape)\n",
    "                label = y_samples[count]\n",
    "                \n",
    "                # Add example to arrays\n",
    "                X_train.append(audio)\n",
    "                y_train.append(label)\n",
    "                wpt.append(Wavelet_1d(audio))\n",
    "\n",
    "\n",
    "            # Make sure they're numpy arrays (as opposed to lists)\n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train)\n",
    "            wpt = np.array(wpt)\n",
    "#             print(\"hello\")\n",
    "            # The generator-y part: yield the next training batch            \n",
    "            yield X_train, wpt, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 20)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wavelet_1d(X_train[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_conv_block(X,in_channels,out_channels,stage,block,dilation=1):\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = BatchNormalization(name=bn_name_base+'a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv1D(in_channels, 3, padding='valid',use_bias = False, name= conv_name_base+'a')(X)\n",
    "    X = BatchNormalization(name=bn_name_base+'b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv1D(in_channels, 3, padding='valid',use_bias = False, name= conv_name_base+'b')(X)\n",
    "    print(X.shape)\n",
    "    paddings = tf.constant([[0, 0],   # the batch size dimension\n",
    "                          [2, 2],   # top and bottom of image\n",
    "                          [0, 0]])  # the channels dimension\n",
    "    X = Lambda(lambda x: tf.pad(x, paddings, mode='CONSTANT',\n",
    "                        constant_values=0.0))(X)\n",
    "    X = concatenate([X , X_shortcut])\n",
    "    X = BatchNormalization(name = bn_name_base+'c')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv1D(out_channels, 3, padding='valid',use_bias = False, dilation_rate = dilation, name = conv_name_base+'c')(X)\n",
    "\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(input_layer, filters, kernel_size=3, activation=\"relu\"):\n",
    "  \n",
    "        output = Conv1D(filters, kernel_size, padding=\"same\", activation=activation)(input_layer)\n",
    "        output = Conv1D(filters, kernel_size, padding=\"same\", activation=activation)(output)\n",
    "        output = Conv1D(filters, kernel_size, padding=\"same\", activation=activation)(output)\n",
    "        output = Conv1D(1,1,padding=\"same\",activation=activation)(output)\n",
    "        print(output.shape,DWT_Pooling()(output).shape)\n",
    "        return output, DWT_Pooling()(output)\n",
    "\n",
    "\n",
    "def up_block(input_layer, residual_layer, filters, kernel_size=3,activation=\"relu\"):\n",
    "        output = Conv1D(1,1,padding=\"same\",activation=activation)(input_layer)\n",
    "        output = IWT_UpSampling()(output)\n",
    "        output = concatenate([residual_layer,output])\n",
    "        output = Conv1D(filters, kernel_size, padding=\"same\", activation=activation)(output)\n",
    "        output = Conv1D(filters, kernel_size, padding=\"same\", activation=activation)(output)\n",
    "        output = Conv1D(filters*2, kernel_size, padding=\"same\", activation=activation)(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwt(x,db2):\n",
    "    # x1_ = tf.placeholder(tf.float32, shape=(None,3200,3), name= 'x1')\n",
    "    dwt = tfwavelets.nodes.dwt1d(x,db2,1)\n",
    "    return dwt\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def iwt(x,db2):\n",
    "    \n",
    "    idwt = tfwavelets.nodes.idwt1d(x,db2,1)\n",
    "    return idwt\n",
    "db2 = tfwavelets.dwtcoeffs.Wavelet(\n",
    "    tfwavelets.dwtcoeffs.Filter(np.array([-0.12940952255092145,\n",
    "                     0.22414386804185735,\n",
    "                     0.836516303737469,\n",
    "                     0.48296291314469025]), 3),\n",
    "    tfwavelets.dwtcoeffs.Filter(np.array([-0.48296291314469025,\n",
    "                     0.836516303737469,\n",
    "                     -0.22414386804185735,\n",
    "                     -0.12940952255092145]), 0),\n",
    "    tfwavelets.dwtcoeffs.Filter(np.array([0.48296291314469025,\n",
    "                     0.836516303737469,\n",
    "                     0.22414386804185735,\n",
    "                     -0.12940952255092145]), 0),\n",
    "    tfwavelets.dwtcoeffs.Filter(np.array([-0.12940952255092145,\n",
    "                     -0.22414386804185735,\n",
    "                     0.836516303737469,\n",
    "                     -0.48296291314469025]), 3)\n",
    ")\n",
    "\n",
    "class DWT_Pooling(Layer):\n",
    "    \"\"\"\n",
    "    # Input shape :\n",
    "        \n",
    "            4D tensor of shape: (batch_size, signal, channels)\n",
    "        \n",
    "            \n",
    "    # Output shape\n",
    "        \n",
    "            4D tensor of shape: (batch_size, signal/2, channels*4)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        super(DWT_Pooling, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(DWT_Pooling, self).build(input_shape) \n",
    "\n",
    "    def call(self, x):\n",
    "        return dwt(x,db2)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \n",
    "        return (input_shape[0], input_shape[1]//2, input_shape[2]*4)\n",
    "\n",
    "\n",
    "class IWT_UpSampling(Layer):\n",
    "    \"\"\"\n",
    "    # Input shape :\n",
    "        \n",
    "            4D tensor of shape: (batch_size, signal, channels)\n",
    "        \n",
    "    # Output shape\n",
    "        \n",
    "            4D tensor of shape: (batch_size, singal*2, channels/4)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(IWT_UpSampling, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(IWT_UpSampling, self).build(input_shape) \n",
    "\n",
    "    def call(self, x):\n",
    "        return iwt(x,db2)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \n",
    "        return (input_shape[0], input_shape[1]*2, input_shape[2]//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unetWavelet(input_size = (3200,1)):\n",
    "\n",
    "input_size = 128,3200,1    \n",
    "\n",
    "# inputs = Input(shape = input_size)\n",
    "inputs= tf.placeholder(tf.float32, shape=input_size, name= 'the_input')\n",
    "down1, pool1 = down_block(inputs,64)\n",
    "print(pool1.shape)\n",
    "down2, pool2 = down_block(pool1,128)\n",
    "down3, pool3 = down_block(pool2,256)\n",
    "down4, pool4 = down_block(pool3,512)\n",
    "\n",
    "down5 = Conv1D(filters=1024, kernel_size= 3, padding=\"same\", activation =\"relu\")(pool4)\n",
    "down5 = Conv1D(filters=1024, kernel_size= 3, padding=\"same\", activation =\"relu\")(down5)\n",
    "down5 = Conv1D(filters=2048, kernel_size= 3, padding=\"same\", activation =\"relu\")(down5)\n",
    "\n",
    "up = up_block(down5,down4,512)\n",
    "up = up_block(up,down3,256)\n",
    "up = up_block(up,down2,128)\n",
    "up = up_block(up,down1,64)\n",
    "\n",
    "MWCNN_output = Conv1D(filters=input_size[1], kernel_size= 1, padding=\"same\")(up)\n",
    "\n",
    "res_conv_1 = res_conv_block(MWCNN_output, 128, 16, 1, 'a', 4)\n",
    "res_conv_2 = res_conv_block(res_conv_1, 16, 8, 2, 'a', 8)\n",
    "res_conv_3 = res_conv_block(res_conv_2, 8, 4, 3, 'a', 16)\n",
    "res_conv_4 = res_conv_block(res_conv_3, 4, 2, 4, 'a', 32)\n",
    "res_conv_5 = res_conv_block(res_conv_4, 2, 1, 5, 'a', 64)\n",
    "\n",
    "res_norm = BatchNormalization(name='res_norm')(res_conv_5)\n",
    "res_relu = Activation('relu')(res_norm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#level three decomposition starts \n",
    "\n",
    "\n",
    "pool_5_1 = AveragePooling1D(pool_size=3, padding='same', name='avg_pool_5_1')(res_relu)\n",
    "flat_5_1 = Flatten(name='flat_5_1')(pool_5_1) \n",
    "\n",
    "fc_5 = Dense(2048, name='fc_5',kernel_initializer = keras.initializers.glorot_uniform(seed=0))(flat_5_1)\n",
    "norm_5 = BatchNormalization(name='norm_5')(fc_5)\n",
    "relu_5 = Activation('relu', name='relu_5')(norm_5)\n",
    "drop_5 = Dropout(0.5, name='drop_5')(relu_5)\n",
    "\n",
    "fc_6 = Dense(2048, name='fc_6',kernel_initializer = keras.initializers.glorot_uniform(seed=0))(drop_5)\n",
    "norm_6 = BatchNormalization(name='norm_6')(fc_6)\n",
    "relu_6 = Activation('relu', name='relu_6')(norm_6)\n",
    "drop_6 = Dropout(0.5, name='drop_6')(relu_6)\n",
    "\n",
    "output = Dense(2, activation=tf.nn.softmax)(drop_6)\n",
    "# model = Model(input = inputs, output = output)\n",
    "    \n",
    "# return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    print(shape)\n",
    "    print(len(shape))\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        print(dim)\n",
    "        variable_parameters *= dim.value\n",
    "    print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "sinc_conv1d_1/filt_b1:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_conv1d_1/filt_band:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_conv1d_1/Variable:0 (float32_ref 251) [251, bytes: 1004]\n",
      "sinc_conv1d_1/Variable_1:0 (float32_ref 125) [125, bytes: 500]\n",
      "sinc_conv1d_1/Variable_2:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_3:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_4:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_5:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_6:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_7:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_8:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_9:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_10:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_11:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_12:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_13:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_14:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_15:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_16:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_17:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_18:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_19:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_20:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_21:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_22:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_23:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_24:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_25:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_26:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_27:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_28:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_29:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_30:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_31:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_32:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_33:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_34:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_35:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_36:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_37:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_38:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_39:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_40:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_41:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_42:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_43:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_44:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_45:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_46:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_47:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_48:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_49:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_50:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_51:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_52:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_53:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_54:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_55:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_56:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_57:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_58:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_59:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_60:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_61:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_62:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_63:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_64:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_65:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_66:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_67:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_68:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_69:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_70:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_71:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_72:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_73:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_74:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_75:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_76:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_77:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_78:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_79:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_80:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_81:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_82:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_83:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_84:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_85:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_86:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_87:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_88:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_89:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_90:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_91:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_92:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_93:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_94:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_95:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_96:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_97:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_98:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_99:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_100:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_101:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_102:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_103:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_104:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_105:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_106:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_107:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_108:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_109:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_110:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_111:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_112:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_113:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_114:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_115:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_116:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_117:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_118:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_119:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_120:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_121:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_122:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_123:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_124:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_125:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_126:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_127:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_128:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_129:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_130:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_131:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_132:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_133:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_134:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_135:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_136:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_137:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_138:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_139:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_140:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_141:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_142:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_143:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_144:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_145:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_146:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_147:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_148:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_149:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_150:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_151:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_152:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_153:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_154:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_155:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_156:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_157:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_158:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_159:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_160:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_161:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_162:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_163:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_164:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_165:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_166:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_167:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_168:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_169:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_170:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_171:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_172:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_173:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_174:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_175:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_176:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_177:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_178:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_179:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_180:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_181:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_182:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_183:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_184:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_185:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_186:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_187:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_188:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_189:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_190:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_191:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_192:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_193:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_194:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_195:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_196:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_197:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_198:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_199:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_200:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_201:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_202:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_203:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_204:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_205:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_206:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_207:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_208:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_209:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_210:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_211:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_212:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_213:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_214:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_215:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_216:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_217:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_218:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_219:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_220:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_221:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_222:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_223:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_224:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_225:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_226:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_227:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_228:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_229:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_230:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_231:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_232:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_233:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_234:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_235:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_236:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_237:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_238:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_239:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_240:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_241:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_242:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_243:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_244:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_245:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_246:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_247:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_248:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_249:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_250:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_251:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_252:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_253:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_254:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_255:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_256:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_conv1d_1/Variable_257:0 (float32_ref 1) [1, bytes: 4]\n",
      "sinc_norm/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm/moving_mean:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm/moving_variance:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_layer_norm/sinc_layer_norm_scale:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_layer_norm/sinc_layer_norm_bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "conv1d_1/kernel:0 (float32_ref 5x64x64) [20480, bytes: 81920]\n",
      "conv1d_1/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm_1/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm_1/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm_1/moving_mean:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_norm_1/moving_variance:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_layer_norm_1/sinc_layer_norm_1_scale:0 (float32_ref 64) [64, bytes: 256]\n",
      "sinc_layer_norm_1/sinc_layer_norm_1_bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "bn1a_brancha/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "bn1a_brancha/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "bn1a_brancha/moving_mean:0 (float32_ref 64) [64, bytes: 256]\n",
      "bn1a_brancha/moving_variance:0 (float32_ref 64) [64, bytes: 256]\n",
      "res1a_brancha/kernel:0 (float32_ref 3x64x128) [24576, bytes: 98304]\n",
      "bn1a_branchb/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "bn1a_branchb/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "bn1a_branchb/moving_mean:0 (float32_ref 128) [128, bytes: 512]\n",
      "bn1a_branchb/moving_variance:0 (float32_ref 128) [128, bytes: 512]\n",
      "res1a_branchb/kernel:0 (float32_ref 3x128x128) [49152, bytes: 196608]\n",
      "bn1a_branchc/gamma:0 (float32_ref 192) [192, bytes: 768]\n",
      "bn1a_branchc/beta:0 (float32_ref 192) [192, bytes: 768]\n",
      "bn1a_branchc/moving_mean:0 (float32_ref 192) [192, bytes: 768]\n",
      "bn1a_branchc/moving_variance:0 (float32_ref 192) [192, bytes: 768]\n",
      "res1a_branchc/kernel:0 (float32_ref 3x192x16) [9216, bytes: 36864]\n",
      "bn2a_brancha/gamma:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_brancha/beta:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_brancha/moving_mean:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_brancha/moving_variance:0 (float32_ref 16) [16, bytes: 64]\n",
      "res2a_brancha/kernel:0 (float32_ref 3x16x16) [768, bytes: 3072]\n",
      "bn2a_branchb/gamma:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_branchb/beta:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_branchb/moving_mean:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn2a_branchb/moving_variance:0 (float32_ref 16) [16, bytes: 64]\n",
      "res2a_branchb/kernel:0 (float32_ref 3x16x16) [768, bytes: 3072]\n",
      "bn2a_branchc/gamma:0 (float32_ref 32) [32, bytes: 128]\n",
      "bn2a_branchc/beta:0 (float32_ref 32) [32, bytes: 128]\n",
      "bn2a_branchc/moving_mean:0 (float32_ref 32) [32, bytes: 128]\n",
      "bn2a_branchc/moving_variance:0 (float32_ref 32) [32, bytes: 128]\n",
      "res2a_branchc/kernel:0 (float32_ref 3x32x8) [768, bytes: 3072]\n",
      "bn3a_brancha/gamma:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_brancha/beta:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_brancha/moving_mean:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_brancha/moving_variance:0 (float32_ref 8) [8, bytes: 32]\n",
      "res3a_brancha/kernel:0 (float32_ref 3x8x8) [192, bytes: 768]\n",
      "bn3a_branchb/gamma:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_branchb/beta:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_branchb/moving_mean:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn3a_branchb/moving_variance:0 (float32_ref 8) [8, bytes: 32]\n",
      "res3a_branchb/kernel:0 (float32_ref 3x8x8) [192, bytes: 768]\n",
      "bn3a_branchc/gamma:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn3a_branchc/beta:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn3a_branchc/moving_mean:0 (float32_ref 16) [16, bytes: 64]\n",
      "bn3a_branchc/moving_variance:0 (float32_ref 16) [16, bytes: 64]\n",
      "res3a_branchc/kernel:0 (float32_ref 3x16x4) [192, bytes: 768]\n",
      "bn4a_brancha/gamma:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_brancha/beta:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_brancha/moving_mean:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_brancha/moving_variance:0 (float32_ref 4) [4, bytes: 16]\n",
      "res4a_brancha/kernel:0 (float32_ref 3x4x4) [48, bytes: 192]\n",
      "bn4a_branchb/gamma:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_branchb/beta:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_branchb/moving_mean:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn4a_branchb/moving_variance:0 (float32_ref 4) [4, bytes: 16]\n",
      "res4a_branchb/kernel:0 (float32_ref 3x4x4) [48, bytes: 192]\n",
      "bn4a_branchc/gamma:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn4a_branchc/beta:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn4a_branchc/moving_mean:0 (float32_ref 8) [8, bytes: 32]\n",
      "bn4a_branchc/moving_variance:0 (float32_ref 8) [8, bytes: 32]\n",
      "res4a_branchc/kernel:0 (float32_ref 3x8x2) [48, bytes: 192]\n",
      "bn5a_brancha/gamma:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_brancha/beta:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_brancha/moving_mean:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_brancha/moving_variance:0 (float32_ref 2) [2, bytes: 8]\n",
      "res5a_brancha/kernel:0 (float32_ref 3x2x2) [12, bytes: 48]\n",
      "bn5a_branchb/gamma:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_branchb/beta:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_branchb/moving_mean:0 (float32_ref 2) [2, bytes: 8]\n",
      "bn5a_branchb/moving_variance:0 (float32_ref 2) [2, bytes: 8]\n",
      "res5a_branchb/kernel:0 (float32_ref 3x2x2) [12, bytes: 48]\n",
      "bn5a_branchc/gamma:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn5a_branchc/beta:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn5a_branchc/moving_mean:0 (float32_ref 4) [4, bytes: 16]\n",
      "bn5a_branchc/moving_variance:0 (float32_ref 4) [4, bytes: 16]\n",
      "res5a_branchc/kernel:0 (float32_ref 3x4x1) [12, bytes: 48]\n",
      "res_norm/gamma:0 (float32_ref 1) [1, bytes: 4]\n",
      "res_norm/beta:0 (float32_ref 1) [1, bytes: 4]\n",
      "res_norm/moving_mean:0 (float32_ref 1) [1, bytes: 4]\n",
      "res_norm/moving_variance:0 (float32_ref 1) [1, bytes: 4]\n",
      "fc_5/kernel:0 (float32_ref 81x2048) [165888, bytes: 663552]\n",
      "fc_5/bias:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_5/gamma:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_5/beta:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_5/moving_mean:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_5/moving_variance:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "fc_6/kernel:0 (float32_ref 2048x2048) [4194304, bytes: 16777216]\n",
      "fc_6/bias:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_6/gamma:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_6/beta:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_6/moving_mean:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "norm_6/moving_variance:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "dense_1/kernel:0 (float32_ref 2048x2) [4096, bytes: 16384]\n",
      "dense_1/bias:0 (float32_ref 2) [2, bytes: 8]\n",
      "Total size of variables: 4494866\n",
      "Total bytes of variables: 17979464\n"
     ]
    }
   ],
   "source": [
    "def model_summary():\n",
    "    model_vars = tf.trainable_variables()\n",
    "    slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n",
    "\n",
    "model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMVZpBEd9EO5"
   },
   "outputs": [],
   "source": [
    "labels = tf.placeholder(tf.float32, shape=(None,2))\n",
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "acc_value = tf.reduce_mean(accuracy(labels, output))\n",
    "# correct_pred = tf.equal(output, labels)\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "from keras.objectives import categorical_crossentropy\n",
    "loss = tf.reduce_mean(categorical_crossentropy(labels, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train_train.npy\")\n",
    "y_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train_train_labels.npy\")\n",
    "y_train = to_categorical(y_train)\n",
    "X_dev_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_train.npy\")\n",
    "X_dev_val = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_val.npy\")\n",
    "y_dev_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_train_labels.npy\")\n",
    "y_dev_val = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_val_labels.npy\")\n",
    "# dev_wpt_levels_data_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_wpt_levels_data_train.npy\")\n",
    "# dev_wpt_levels_data_val = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_dev_wpt_levels_data_val.npy\")\n",
    "# wpt_levels_data_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train_wpt_levels_data_train.npy\")\n",
    "X_val = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train_val.npy\")\n",
    "y_val = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train_val_labels.npy\")\n",
    "y_val = to_categorical(y_val)\n",
    "# wpt_levels_data_val = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train_wpt_levels_data_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_wpt_levels_data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ab331591e1c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdev_wpt_levels_data_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev_wpt_levels_data_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwpt_levels_data_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev_wpt_levels_data_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_wpt_levels_data_train' is not defined"
     ]
    }
   ],
   "source": [
    "dev_wpt_levels_data_train.shape,dev_wpt_levels_data_val.shape,wpt_levels_data_train.shape,dev_wpt_levels_data_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging dev_train and dev_val with x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.concatenate([X_train,X_dev_train,X_dev_val])\n",
    "y_train=np.concatenate([y_train,to_categorical(y_dev_train),to_categorical(y_dev_val)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "colab_type": "code",
    "id": "SYedzAue9ERm",
    "outputId": "18c403b6-383f-46bf-cdd7-76e009fb4b07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "((128, 3200, 1), (128, 3200, 1), (128, 2))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_l1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-cbbe98b005a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_l1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#             print(sess.run(output,feed_dict))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_l1' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "# X_batch = np.array((batch_size,75673))\n",
    "# y_train = np.array((batch_size))\n",
    "train_step = tf.train.RMSPropOptimizer(0.001).minimize(loss)\n",
    "\n",
    "# Initialize all variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "step = 0\n",
    "# Run training loop\n",
    "with sess.as_default():\n",
    "    for i in range(1):\n",
    "        for X_batch, wpt, y_batch in generator(X_train, y_train, 128):\n",
    "            step = step + 1\n",
    "            print(step)\n",
    "            print(X_batch.shape,wpt.shape,y_batch.shape)\n",
    "            feed_dict = {input_: X_batch, labels: y_batch, input_l1: wpt, K.learning_phase(): 1}\n",
    "            sess.run(train_step,feed_dict)\n",
    "#             print(sess.run(output,feed_dict))\n",
    "            if step % 1 == 0:\n",
    "                loss_val,acc_val = (sess.run([loss,acc_value],feed_dict))\n",
    "                print(\"Epoch: \"+str(i)+\"step: \"+str(step)+\"Training loss: \",loss_val,\" \",\"Training accuracy\",\" \",acc_val)\n",
    "                loss_val,acc_val = (sess.run([loss,acc_value],feed_dict={input_: X_batch, labels: y_batch, input_l1: wpt, K.learning_phase(): 0}))\n",
    "                print(\"Epoch: \"+str(i)+\"step: \"+str(step)+\"loss: \",loss_val,\" \",\"accuracy\",\" \",acc_val)\n",
    "    for X_batch, wpt, y_batch in generator(X_val, y_val, 128):\n",
    "        loss_val_val,acc_val_val = (sess.run([loss,acc_value],feed_dict={input_: X_batch, labels: y_batch, input_l1: wpt, K.learning_phase(): 0}))\n",
    "        print(\"val loss: \",loss_val_val,\" \",\"val accuracy\",\" \",acc_val_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "# X_batch = np.array((batch_size,75673))\n",
    "# y_train = np.array((batch_size))\n",
    "train_step = tf.train.RMSPropOptimizer(0.001).minimize(loss)\n",
    "\n",
    "# Initialize all variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "step = 0\n",
    "# Run training loop\n",
    "with sess.as_default():\n",
    "    for i in range(1):\n",
    "        for X_batch, y_batch in generator(X_train, y_train, 128):\n",
    "            step = step + 1\n",
    "            print(step)\n",
    "            print(X_batch.shape,y_batch.shape)\n",
    "            feed_dict = {input_: X_batch, labels: y_batch, K.learning_phase(): 1}\n",
    "            sess.run(train_step,feed_dict)\n",
    "#             print(sess.run(output,feed_dict))\n",
    "            loss_val,acc_val = (sess.run([loss,acc_value],feed_dict))\n",
    "            print(\"Epoch: \"+str(i)+\"step: \"+str(step)+\"Training loss: \",loss_val,\" \",\"Training accuracy\",\" \",acc_val)\n",
    "            loss_val,acc_val = (sess.run([loss,acc_value],feed_dict={input_: X_batch, labels: y_batch, K.learning_phase(): 0}))\n",
    "            print(\"Epoch: \"+str(i)+\"step: \"+str(step)+\"loss: \",loss_val,\" \",\"accuracy\",\" \",acc_val)\n",
    "            if step % 2000 == 0:\n",
    "                step_val = 0    \n",
    "                for X_batch, y_batch in generator_val(X_val, y_val, 128):\n",
    "                    step_val = step_val + 1\n",
    "                    loss_val_val,acc_val_val = (sess.run([loss,acc_value],feed_dict={input_: X_batch, labels: y_batch, K.learning_phase(): 0}))\n",
    "                    print(\"val loss: \",loss_val_val,\" \",\"val accuracy\",\" \",acc_val_val)\n",
    "                    if step_val == 1000:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train_train.npy\")\n",
    "y_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train_train_labels.npy\")\n",
    "wpt_levels_data_train = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/ASVspoof2019_train_wpt_levels_data_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjXYvZGX6VYn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3611,), (3611, 4))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, wpt_levels_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L3R6e3kO9EWq",
    "outputId": "96b96120-9550-4d42-fd22-2a38a5711b8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "\n",
    "acc_value = accuracy(labels, preds)\n",
    "with sess.as_default():\n",
    "    print(acc_value.eval(feed_dict={img: mnist_data.test.images,\n",
    "                                    labels: mnist_data.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qCjupTcM-gJF",
    "outputId": "43c4032f-0f54-4f2b-8277-7911858d296b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.chunking at 0x7f2d70eeaa58>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunking(X_train,y_train,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pjQBjVYNWkvE",
    "outputId": "408bcc88-5f9f-40df-beb5-4a2eed8f6a60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.load(\"/content/drive/My Drive/SA/Code/spoof_detection_deep_features/WaveletCNN/temp_npy/labels_train.npy\",mmap_mode='r')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0HzJnZ4e_PJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WaveletCNN_Latest_ASVspoof2015.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
