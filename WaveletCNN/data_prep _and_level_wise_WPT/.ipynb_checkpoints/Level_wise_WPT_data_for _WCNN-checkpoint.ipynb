{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24287,
     "status": "ok",
     "timestamp": 1583429502753,
     "user": {
      "displayName": "Rohit Arora",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giutc51X9fjwvH53IqxO8CGT0SR9FudqJV1MJXb=s64",
      "userId": "15885060245314397173"
     },
     "user_tz": -330
    },
    "id": "kmNhZdJyHBgf",
    "outputId": "d0f3989e-8a4a-48e1-d8a6-2856d7a2ebe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25091,
     "status": "ok",
     "timestamp": 1583429504507,
     "user": {
      "displayName": "Rohit Arora",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giutc51X9fjwvH53IqxO8CGT0SR9FudqJV1MJXb=s64",
      "userId": "15885060245314397173"
     },
     "user_tz": -330
    },
    "id": "pEK0wkpdiIUB",
    "outputId": "e19d2db3-2c09-4df9-9519-5a7423e3c6eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/SA/Code/spoof_detection_deep_features/WaveletCNN\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/SA/Code/spoof_detection_deep_features/WaveletCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpqXklEViIW6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named sincnet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ff6332415ee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msincnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m# from tensorflow import set_random_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named sincnet"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import to_categorical,Sequence\n",
    "import pandas as pd\n",
    "import math\n",
    "import sincnet\n",
    "# from tensorflow import set_random_seed\n",
    "from keras import models, layers\n",
    "import numpy as np\n",
    "import sincnet\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import MaxPooling1D,MaxPooling2D, Conv1D, LeakyReLU, BatchNormalization, Dense, Flatten\n",
    "from keras.layers import InputLayer, Input\n",
    "from keras.models import Model\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pywt\n",
    "from sklearn.decomposition import PCA\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UOii2GXSiFqd"
   },
   "outputs": [],
   "source": [
    "def framing_windowing(signal):\n",
    "    pre_emphasis = 0.97\n",
    "    frame_size = 256\n",
    "    frame_stride = 128\n",
    "    nfilt = 20\n",
    "    emphasized_signal = np.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "    frame_length, frame_step = frame_size, frame_stride  # Convert from seconds to samples\n",
    "    signal_length = len(emphasized_signal)\n",
    "    frame_length = int(round(frame_length))\n",
    "    frame_step = int(round(frame_step))\n",
    "    num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
    "#     print(num_frames)\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = np.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = np.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "    frames *= np.hamming(frame_length)\n",
    "    # print(frames.shape)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTT2NAbriIZm"
   },
   "outputs": [],
   "source": [
    "def tkeo(a):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the TKEO of a given recording by using 2 samples.\n",
    "    See Li et al., 2007\n",
    "    Arguments:\n",
    "    a \t\t\t--- 1D numpy array.\n",
    "    Returns:\n",
    "    1D numpy array containing the tkeo per sample\n",
    "    \"\"\"\n",
    "    # Create two temporary arrays of equal length, shifted 1 sample to the right\n",
    "    # and left and squared:\n",
    "    i = a[1:-1]*a[1:-1]\n",
    "    j = a[2:]*a[:-2]\n",
    "    # Calculate the difference between the two temporary arrays:\n",
    "    aTkeo = i-j\n",
    "    return aTkeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-D3visVXiIcJ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'framing_windowing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0de0d2504782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mNFFT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m511\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframing_windowing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# signal = tkeo(signal)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNFFT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnfilt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'framing_windowing' is not defined"
     ]
    }
   ],
   "source": [
    "def Wavelet_1d(signal):\n",
    "    import numpy\n",
    "    pre_emphasis = 0.97\n",
    "frame_size = 256\n",
    "frame_stride = 128\n",
    "nfilt = 20\n",
    "NFFT = 511\n",
    "sample_rate = 16000\n",
    "signal = framing_windowing(signal)\n",
    "# signal = tkeo(signal)\n",
    "mel = lb.filters.mel(sr=sample_rate, n_fft=NFFT, n_mels=nfilt)\n",
    "audio_features1 = []\n",
    "audio_features2 = []\n",
    "audio_features3 = []\n",
    "audio_features4 = []\n",
    "# print(\"signal shape\",signal.shape)\n",
    "for f in signal:\n",
    "    tke = tkeo(f)\n",
    "    data_std = StandardScaler().fit_transform(tke.reshape(-1,1)).reshape(1,-1)[0]            \n",
    "    wptree = pywt.WaveletPacket(data=data_std, wavelet='db1', mode='symmetric')\n",
    "    level1 = wptree.get_level(1, order = \"freq\")\n",
    "    level2 = wptree.get_level(2, order = \"freq\")\n",
    "    level3 = wptree.get_level(3, order = \"freq\")\n",
    "    level4 = wptree.get_level(4, order = \"freq\")\n",
    "    # print(\"level1 data array:\",np.array(level1).shape)\n",
    "    # print(\"level2 data array:\",np.array(level2).shape)\n",
    "    # print(\"level3 data array:\",np.array(level3).shape)\n",
    "    # print(\"level4 data array:\",np.array(level4).shape)          \n",
    "      #Feature extraction for each node\n",
    "    frame_features1 = []\n",
    "    frame_features2 = []\n",
    "    frame_features3 = []\n",
    "    frame_features4 = []        \n",
    "    for node in level1:\n",
    "        data_wp = node.data\n",
    "      # print(\"WP data:\",np.array(data_wp).shape)\n",
    "      # Features group\n",
    "        frame_features1.extend(data_wp)\n",
    "    # print(\"frame_features1\",np.array(frame_features1).shape)\n",
    "    mag_frames = numpy.absolute(frame_features1)  # Magnitude of the FFT\n",
    "    pow_frames = numpy.abs((mag_frames) ** 2)\n",
    "    z = mel.shape[1] - pow_frames.shape[0]\n",
    "    pow_frames = np.pad(pow_frames,[(0,z)],'constant', constant_values=0)\n",
    "    # print(\"pow_frames\",pow_frames.shape)\n",
    "    mel_scaled_features = mel.dot(pow_frames)\n",
    "    audio_features1.append(mel_scaled_features)\n",
    "    \n",
    "\n",
    "    for node in level2:\n",
    "        data_wp = node.data\n",
    "      # print(\"WP data:\",np.array(data_wp).shape)\n",
    "      # Features group\n",
    "        frame_features2.extend(data_wp)\n",
    "    mag_frames = numpy.absolute(frame_features2)  # Magnitude of the FFT\n",
    "    pow_frames = numpy.abs((mag_frames) ** 2)\n",
    "    mel_scaled_features = mel.dot(pow_frames)\n",
    "    audio_features2.append(mel_scaled_features)\n",
    "    for node in level3:\n",
    "        data_wp = node.data\n",
    "      # print(\"WP data:\",np.array(data_wp).shape)\n",
    "      # Features group\n",
    "        frame_features3.extend(data_wp)\n",
    "    mag_frames = numpy.absolute(frame_features3)  # Magnitude of the FFT\n",
    "    pow_frames = numpy.abs((mag_frames) ** 2)\n",
    "    mel_scaled_features = mel.dot(pow_frames)\n",
    "    audio_features3.append(mel_scaled_features)\n",
    "    for node in level4:\n",
    "        data_wp = node.data\n",
    "      # print(\"WP data:\",np.array(data_wp).shape)\n",
    "      # Features group\n",
    "        frame_features4.extend(data_wp)\n",
    "    mag_frames = numpy.absolute(frame_features4)  # Magnitude of the FFT\n",
    "    pow_frames = numpy.abs((mag_frames) ** 2)\n",
    "    mel_scaled_features = mel.dot(pow_frames)\n",
    "    audio_features4.append(mel_scaled_features)\n",
    "    \n",
    "  # print(\"audio_features1:\",np.array(audio_features1).shape)\n",
    "  # print(\"audio_features1:\",np.array(audio_features2).shape)\n",
    "  # print(\"audio_features1:\",np.array(audio_features3).shape)\n",
    "  # print(\"audio_features1:\",np.array(audio_features4).shape)\n",
    "#     print(\"hello\")\n",
    "    log_energy1 = numpy.log10(audio_features1)\n",
    "    log_energy1 = pd.DataFrame(log_energy1)\n",
    "    log_energy2 = numpy.log10(audio_features2)\n",
    "    log_energy2 = pd.DataFrame(log_energy2)\n",
    "    log_energy3 = numpy.log10(audio_features3)\n",
    "    log_energy3 = pd.DataFrame(log_energy3)\n",
    "    log_energy4 = numpy.log10(audio_features4)\n",
    "    log_energy4 = pd.DataFrame(log_energy4)\n",
    "    pd.set_option('use_inf_as_na', True)\n",
    "    log_energy1=log_energy1.fillna(log_energy1.mean())\n",
    "    log_energy1 = np.array(log_energy1)\n",
    "    log_energy2=log_energy2.fillna(log_energy2.mean())\n",
    "    log_energy2 = np.array(log_energy2)\n",
    "    log_energy3=log_energy3.fillna(log_energy3.mean())\n",
    "    log_energy3 = np.array(log_energy3)\n",
    "    log_energy4=log_energy4.fillna(log_energy4.mean())\n",
    "    log_energy4 = np.array(log_energy4)\n",
    "  # print(\"log_energy1: \",log_energy1.shape)\n",
    "  # print(\"log_energy2: \",log_energy2.shape)\n",
    "  # print(\"log_energy3: \",log_energy3.shape)\n",
    "  # print(\"log_energy4: \",log_energy4.shape)\n",
    "  # signals_level1[count] = np.array(log_energy1)\n",
    "  # signals_level2[count] = np.array(log_energy2)\n",
    "  # signals_level3[count] = np.array(log_energy3)\n",
    "  # signals_level4[count] = np.array(log_energy4)\n",
    "  # print(signals_level1.shape)\n",
    "  # print(signals_level2.shape)\n",
    "  # print(signals_level3.shape)\n",
    "  # print(signals_level4.shape)  \n",
    "\n",
    "    return log_energy1,log_energy2,log_energy3,log_energy4\n",
    "\n",
    "def Wavelet_out_shape(input_shapes):\n",
    "    # print('in to shape')\n",
    "    return [tuple([None, 590, 20]), tuple([None, 590, 20]), \n",
    "            tuple([None, 590, 20]), tuple([None, 590, 20])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRtAWGdBjHsc"
   },
   "outputs": [],
   "source": [
    "train_labels = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/train_label.npy\")\n",
    "trimmed_audio = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/trimmed_audio.npy\",mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1507,
     "status": "ok",
     "timestamp": 1583434333886,
     "user": {
      "displayName": "Rohit Arora",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giutc51X9fjwvH53IqxO8CGT0SR9FudqJV1MJXb=s64",
      "userId": "15885060245314397173"
     },
     "user_tz": -330
    },
    "id": "gA8dr1enx5TC",
    "outputId": "d9cfc6e3-64bf-4637-89f7-0892d58b6d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ": boolean\n",
      "    use_inf_as_null had been deprecated and will be removed in a future\n",
      "    version. Use `use_inf_as_na` instead.\n",
      "\n",
      "wpt shape (4, 590, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:82: RuntimeWarning: divide by zero encountered in log10\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:84: RuntimeWarning: divide by zero encountered in log10\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: divide by zero encountered in log10\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:88: RuntimeWarning: divide by zero encountered in log10\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/_config/config.py:622: FutureWarning: \n",
      ": boolean\n",
      "    use_inf_as_null had been deprecated and will be removed in a future\n",
      "    version. Use `use_inf_as_na` instead.\n",
      "\n",
      "  warnings.warn(d.msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "wpt = Wavelet_1d(trimmed_audio[1])\n",
    "print(\"wpt shape\",wpt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 81878,
     "status": "ok",
     "timestamp": 1583435827938,
     "user": {
      "displayName": "Rohit Arora",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giutc51X9fjwvH53IqxO8CGT0SR9FudqJV1MJXb=s64",
      "userId": "15885060245314397173"
     },
     "user_tz": -330
    },
    "id": "gRhAiWW6jIuy",
    "outputId": "9a7026e0-a4df-49da-f3b5-1b4d60ed97b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "(100, 4, 590, 20)\n"
     ]
    }
   ],
   "source": [
    "wpt_levels_data = []\n",
    "for count,i in enumerate(trimmed_audio[:100]):\n",
    "    if count%10 == 0:\n",
    "        print(count)\n",
    "    level1,level2,level3,level4 = Wavelet_1d(i)\n",
    "    wpt_levels_data.append([level1,level2,level3,level4])\n",
    "wpt_levels_data = np.array(wpt_levels_data)\n",
    "np.save(\"/home/rohita/rohit/spoof/npy_data_asvspoof/wpt_levels_data.npy\",wpt_levels_data)\n",
    "print(wpt_levels_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cvpOgVq__1X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO8VapFBXNzOqilvdNBgxpn",
   "name": "Level_wise_WPT_data_for _WCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
